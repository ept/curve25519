\documentclass[manuscript]{acmart}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools} % dcases environment
\usepackage{tikz}

% The minted package does source code syntax highlighting using Pygments: https://pygments.org/
% Pygments must be installed on your system, e.g. using `pip3.8 install Pygments`.
% pdflatex must be run with option -shell-escape so that it can run pygmentize.
% To allow the document to be built on systems without Pygments, commit the files in the
% _minted-curve25519/ directory to git. Use option finalizecache=true to update the cached
% syntax-highlighted listings, and use option frozencache=true to use that cache.
% With frozencache=true, the -shell-escape option is no longer needed.
\usepackage[frozencache=true]{minted}

\begin{document}
\def\listingautorefname{Listing}%
\def\sectionautorefname{Section}%
\def\subsectionautorefname{Section}%
\def\subsubsectionautorefname{Section}%

\title{Implementing Curve25519/X25519: A Tutorial on Elliptic Curve Cryptography}

\author{Martin Kleppmann}
\email{mk428@cst.cam.ac.uk}
\orcid{0000-0001-7252-6958}
\affiliation{%
  \institution{University of Cambridge}
  \department{Department of Computer Science and Technology}
  \streetaddress{15 JJ Thomson Avenue}
  \city{Cambridge}
  \postcode{CB3 0FD}
  \country{United Kingdom}
}

\begin{abstract}
Many textbooks cover the concepts behind Elliptic Curve Cryptography, but few explain how to go from the equations to a working, fast, and secure implementation.
On the other hand, while the code of many cryptographic libraries is available as open source, it can be rather opaque to the untrained eye, and it is rarely accompanied by detailed documentation explaining how the code came about and why it is correct.
This tutorial bridges the gap between the mathematics and implementation of elliptic curve cryptography.
It is written for readers who are new to cryptography, and it assumes very little mathematical background.
Starting from first principles, this paper shows how to derive every line of code in an implementation of the X25519 Diffie-Hellman key agreement scheme, based on the Curve25519 elliptic curve.
The implementation is fast and secure; in particular, it is constant-time to prevent side-channel attacks.
\end{abstract}

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10002978.10002979.10002981.10011745</concept_id>
       <concept_desc>Security and privacy~Public key encryption</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10003752.10003777.10003788</concept_id>
       <concept_desc>Theory of computation~Cryptographic primitives</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Security and privacy~Public key encryption}
\ccsdesc[500]{Theory of computation~Cryptographic primitives}

\keywords{elliptic curve cryptography, Diffie-Hellman key agreement, implementation of cryptographic algorithms, constant-time algorithms, resistance to side-channel attacks}
\setcopyright{none}
\maketitle

\section{Introduction}

Curve25519~\cite{Bernstein:2006kw} is a very widely deployed elliptic curve: it is used for Diffie-Hellman key agreement in the X25519 standard~\cite{X25519}, which is a mandatory algorithm in TLS 1.3~\cite{TLS13}, securing a huge number of HTTPS connections in web browsers worldwide.
It is also used for encryption in WhatsApp~\cite{WhatsAppWhitepaper}, Signal~\cite{Marlinspike:2016}, and many other systems and protocols~\cite{UseCurve25519}.
However, the standard textbooks on elliptic curve cryptography \cite{Blake:1999,Cohen:2006,Hankerson:2004,Koblitz:1994} predate Curve25519, and there are not many good resources that explain how practical implementations of this algorithm actually work.
Glancing at an implementation of X25519 (see, for example, \autoref{code:scalarmult} on page~\pageref{code:scalarmult}, or Section 5 of the X25519 standard document~\cite{X25519}) reveals mysterious sequences of arithmetic operations with few comments, explanation, or justification.

The goal of this tutorial is to provide an introduction to elliptic curve cryptography by means of carefully analysing every line of code of one particular implementation of X25519.
We show how the algorithm is derived from basic principles, walking through the algebraic derivations step by step, and justifying their correctness.
No advanced mathematics background is required: all that is needed is some basic modular arithmetic, which should be covered in most undergraduate computer science courses.

The implementation we analyse is based on TweetNaCl~\cite{Bernstein:2014ca,TweetNaCl}, a small but practical cryptography library with the same API as NaCl~\cite{NaCl,Bernstein:2012}.
The name derives from the fact that the implementation fits in 100 tweets of up to 140 characters each.
TweetNaCl is originally written in C, but its simplicity has made it popular for porting to various other languages, such as JavaScript~\cite{TweetNaCljs}.
Despite its simplicity, TweetNaCl has strong security properties that we expect of fully-fledged cryptography libraries: in particular, it uses constant-time algorithms to prevent side-channel attacks (that is, it performs no branches or array lookups based on secret values).
Compared to the original TweetNaCl implementation~\cite{TweetNaCl}, the code in this paper has been slightly reformatted and simplified to improve readability, while leaving functionality, security, and performance unchanged (the changes are detailed in \autoref{sec:appendix}).

TweetNaCl advertises itself as ``auditable''~\cite{Bernstein:2014ca} in the sense that its code is short and simple enough that its correctness can be established through code review.
However, to my knowledge, no detail of any such audit has been published.
The JavaScript port has indeed been professionally audited, but the report~\cite{TweetNaClAudit} does not go into any technical detail.
Previous analyses of NaCl/TweetNaCl~\cite{Bernstein:2009,Janssen:2014} give justification for some of the algorithms, but also leave many details unexplained.
This paper partially fills that gap: we discuss only X25519, but not the other algorithms that appear in TweetNaCl, such as the Salsa20 stream cipher, the Poly1305 authenticator, or the Ed25519 signature scheme.

Unlike HACL*~\cite{HACLStar}, which contains a formally verified implementation of X25519~\cite{Zinzindohoue:2017fc}, the goal of this paper is not so much to verify that TweetNaCl is correct, but rather to teach how secure implementations of elliptic curve cryptography work by carefully studying one particular algorithm and its implementation.

\section{Background}\label{sec:background}

This section briefly introduces the mathematical tools and concepts that are needed for later sections.

\subsection{Modular arithmetic}\label{sec:modular-arithmetic}

The set of \emph{integers modulo} $p$ is $\mathbb{Z}_p = \{0, 1, \dots, p-1\} = [0,\, p-1]$.
In cryptography, computations are often performed modulo $p$.
This means that if a calculation would return a result outside of the range of 0 to $p-1$, we let it ``wrap around'' by adding or subtracting $p$ until we get a number between 0 and $p-1$, inclusive.

For example, if we are working modulo 7, then $1+1=2$, $2+1=3$, \dots, $5+1=6$, but $6+1$ wraps around to $0$.
We write this as $6+1 \equiv 0 \pmod{7}$.
This is similar to unsigned integer overflow in the C programming language, where e.g.\ operations on unsigned 32-bit integers are performed modulo $2^{32}$.

In general, we say that two integers $a, b \in \mathbb{Z}$ are \emph{congruent modulo $p$}, written $a \equiv b \pmod{p}$, if and only if there exists $k \in \mathbb{Z}$ such that $a - b = kp$.
That is, we can convert between $a$ and $b$ by adding or subtracting $p$ repeatedly.
When we bring a number within the range of $[0,\, p-1]$ by adding or subtracting multiples of $p$, we call that process \emph{reduction modulo $p$}.

The $\equiv$ operator for congruence modulo $p$ behaves in many ways like an equals sign.
For example, if $a \equiv b \pmod{p}$, then $a+c \equiv b+c \pmod{p}$, and $a \cdot c \equiv b \cdot c \pmod{p}$.
That is, we can substitute one expression for another expression if those expressions are congruent modulo $p$.

This means that when a calculation is performed modulo $p$, we can reduce modulo $p$ after each step of the calculation.
For example, say we want to calculate $3 \cdot (5 + 6)$ modulo 7.
Then we can first calculate $5+6$ and reduce it modulo $7$, i.e.\ $5+6 = 11 \equiv 4 \pmod{7}$, and then calculate $3 \cdot 4 = 12 \equiv 5 \pmod{7}
$.
The result is the same as if we calculated $3 \cdot (5 + 6) = 3 \cdot 11 = 33 = 4 \cdot 7 + 5 \equiv 5 \pmod{7}$.

Reduction modulo $p$ is very useful when performing calculations on a computer, since it allows us to represent values in a fixed number of bits.
For example, if $0 < p \le 2^n$, any number in $\mathbb{Z}_p$ fits in $n$ bits.

In cryptography, $p$ is often a large prime number.
For example, Curve25519 uses arithmetic modulo the prime number $p=2^{255}-19=\verb|0x7fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffed|$ in hexadecimal (hence the name of the curve), so the numbers in the curve calculations fit in 255 bits (just under 32 bytes).
We can use open source mathematics software SageMath to check that $p$ is indeed a prime:
\begin{minted}{python}
    (2^255 - 19).is_prime() # returns True
\end{minted}

\subsection{Groups}\label{sec:groups}

An \emph{abelian group} is a set $E$ together with an operation $\bullet$.
The operation combines two elements of the set, denoted $a \bullet b$ for $a, b \in E$.
Moreover, the operation must satisfy the following requirements:
\begin{description}
\item[Closure:] For all $a, b \in E$, the result of the operation $a \bullet b$ is also in $E$.
\item[Commutativity:] For all $a, b \in E$ we have $a \bullet b = b \bullet a$.
\item[Associativity:] For all $a, b, c \in E$ we have $(a \bullet b) \bullet c = a \bullet (b \bullet c)$.
\item[Identity element:] There exists an element $e \in E$, called the \emph{identity element} or \emph{neutral element}, such that for all $a \in E$ we have $e \bullet a = a \bullet e = a$.
\item[Inverse element:] For every $a \in E$ there exists an element $b \in E$ such that $a \bullet b = b \bullet a = e$, where $e$ is the identity element. We then call $b$ the \emph{inverse} of $a$, written $b = a^{-1}$, and vice versa ($a = b^{-1}$).
\end{description}

A non-abelian group has all of the above properties apart from commutativity, but all the groups we deal with in this paper are abelian.
The number of elements in $E$ is called the \emph{order} of the group.
A group is a very useful abstraction since it has many nice mathematical properties, especially if the number of elements in $E$ is a prime number (this is called a \emph{prime order group}).

There are many possible ways of constructing a group.
For example, the set of (positive and negative) integers $\mathbb{Z}$ together with the addition operator $+$ forms a group with identity element $0$, where the inverse of element $a \in \mathbb{Z}$ is $-a$.
This group is infinite, since there are an infinite number of integers $\mathbb{Z}$.

To construct a finite group, we can use $\mathbb{Z}_p$, the set of integers modulo $p$, and the group operator is addition $+$ followed by reduction modulo $p$.
This group has identity element $0$, and the inverse of $a \in \mathbb{Z}_p$ is $p-a$.
This construction is called the \emph{additive group of integers modulo $p$}.

Another finite group construction uses as elements the set of integers $\mathbb{Z}_p^* = \{1,\dots, p-1\} = \mathbb{Z}_p \setminus \{0\}$, where $p$ is a prime number, and the group operator is multiplication $\cdot$ followed by reduction modulo $p$.
This group is known as the \emph{multiplicative group of integers modulo $p$}, and it has identity element $1$.
It is not obvious that every element $a \in \{1,\dots, p-1\}$ has an inverse (also called \emph{multiplicative inverse}), but this fact can be shown using Bézout's identity when $p$ is prime, and it is covered in many textbooks on number theory.
In \autoref{sec:cyclic} we will see an algorithm for computing the multiplicative inverse.

Finally, in \autoref{sec:group-construction} we will use elliptic curves to construct another type of finite group.
This group forms the foundation of most algorithms in elliptic curve cryptography.

Many cryptographic algorithms and protocols use a group without specifying how that group should be implemented.
This works because any two groups with the same prime order are \emph{isomorphic} to each other: that is, one group can be transformed into the other by renaming elements.
Thus, informally speaking, two groups with the same prime order ``behave the same'', regardless of how they are implemented (although their security properties may differ).
This makes the concept of a group one of the most common and useful abstractions in cryptography.

\subsection{Diffie-Hellman key exchange}\label{sec:diffie-hellman}

A common use of groups in cryptography is the \emph{Diffie-Hellman key exchange}, which allows two parties (Alice and Bob) to establish a shared secret by communicating over an insecure channel, under the assumption that the adversary can only observe but not modify the communication.
This shared secret can then be used as a key to encrypt messages between the two parties.
If the adversary may actively interfere with the communication, additional authentication is required, which we do not discuss here.

For a group element $g$ and a non-negative integer $k$ we define the repeated application of the group operator to $g$ as follows:
\begin{equation}\label{eq:power}
    g^k = \underbrace{g \bullet g \bullet \cdots \bullet g}_\text{$k$ times} \quad\text{or, recursively:}\quad
    g^0 = e \quad\text{(the identity element), and}\quad g^k = g \bullet g^{k-1} \quad\text{for } k>0.
\end{equation}
We show in \autoref{sec:ladder} how to compute $g^k$ efficiently in the Curve25519 group, even for large $k$.

Let's say that Bob wants anybody to be able to send him encrypted messages, which we can do using Diffie-Hellman.
Bob must first generate a keypair consisting of a private and public key, and make the public key available to anybody.
To generate his keypair, Bob chooses a random integer $j$ as his private key, and computes $g^j$ for a well-known group element $g$.
This group element $g$ is called the \emph{base point} or \emph{generator}, and we will see later how it is chosen.
The group element $g^j$ is Bob's public key.

When Alice wants to send an encrypted message to Bob, she obtains Bob's public key $g^j$ and chooses a random integer $k$.
She computes $(g^j)^k$ and uses the result as a key for a symmetric cipher to encrypt her message to Bob.
She also computes $g^k$ and sends this group element to Bob along with her message, while $k$ remains private.
When Bob receives $g^k$ from Alice, he uses his private key $j$ to compute:
\begin{equation*}
(g^k)^j =
\underbrace{(\underbrace{g \bullet\cdots\bullet g}_\text{$k$ times}) \bullet\cdots\bullet (\underbrace{g \bullet\cdots\bullet g}_\text{$k$ times})}_\text{$j$ times} =
\underbrace{g \bullet\cdots\bullet g}_\text{$j \cdot k$ times} =
\underbrace{(\underbrace{g \bullet\cdots\bullet g}_\text{$j$ times}) \bullet\cdots\bullet (\underbrace{g \bullet\cdots\bullet g}_\text{$j$ times})}_\text{$k$ times} =
(g^j)^k
\end{equation*}

Due to the associativity of $\bullet$, the group element $(g^k)^j$ computed by Bob equals the value $(g^j)^k$ that Alice used to encrypt her message.
Thus, Alice and Bob obtain the same shared secret, and Bob can decrypt Alice's message.
An adversary knows $g$ and $g^j$ (since they are public) and may learn $g^k$ by eavesdropping as it is sent over the network.
For the Diffie-Hellman key exchange to be secure, it must be computationally extremely difficult for the adversary to compute $g^{jk}$ given $g$, $g^j$, and $g^k$.

\subsection{Security properties of groups}\label{sec:cdh-ddh}

The Diffie-Hellman protocol is secure if the following assumptions are true (where $i$, $j$ and $k$ are chosen uniformly at random from $\mathbb{Z}_p$ for sufficiently large $p$):

\begin{description}
\item[Hardness of discrete logarithms:]
    Given $g$ and $g^k$, it is not feasible for the adversary to compute $k$.
\item[Computational Diffie-Hellman (CDH) assumption:]
    Given $g$, $g^j$, and $g^k$, it is not feasible for the adversary to compute $g^{jk}$.
\item[Decisional Diffie-Hellman (DDH) assumption:]
    The adversary is given one of two tuples, either $(g, g^j, g^k, g^{jk})$ or $(g, g^j, g^k, g^i)$, chosen at random with equal probability.
    Then the adversary must choose whether it was given the tuple containing $g^{jk}$ or the tuple containing the random group element $g^i$.
    The DDH assumption then states that it is not feasible for the adversary to choose the correct answer with probability significantly greater than $\frac{1}{2}$ (a random guess).
\end{description}

If the adversary can compute discrete logarithms, they can compute $j$ and/or $k$ from $g^j$ and $g^k$, and hence they can compute $g^{jk}$; therefore, assuming CDH implies assuming that discrete logarithms are hard.
Moreover, if the adversary can compute $g^{jk}$ then they can tell the difference between $g^{jk}$ and $g^i$, and therefore assuming DDH implies assuming CDH.
However, the converse is not necessarily true: for example, it might be possible to compute $g^{jk}$ directly from $g^j$ and $g^k$, without first computing $j$ or $k$, although no such algorithm is currently known.

How do the groups from \autoref{sec:groups} fare with respect to these security properties?
\begin{itemize}
\item In the additive group of integers modulo $p$, discrete logarithms are easy to compute, so this group is not secure.
    Computing $g^k$ in this group means adding $g$ to itself $k$ times, which is the same as computing the product $g \cdot k$.
    We can compute the multiplicative inverse of $g$ (\autoref{sec:cyclic}) and then compute $g^{-1} \cdot g \cdot k = k$ in order to efficiently recover $k$.

\item In $\mathbb{Z}_p^*$, the multiplicative group of integers modulo $p$, discrete logarithms are believed to be hard, but the DDH assumption does not hold.
    A detailed explanation goes beyond the scope of this paper, but it can be stated briefly: the adversary can use Euler's criterion to determine whether $g^k$ is a quadratic residue modulo $p$, which leaks the least significant bit of $k$ (i.e.\ whether $k$ is odd or even).
    Moreover, $jk$ is even if and only if $j$ and/or $k$ is even.
    Thus, if the adversary is given $(g, g^j, g^k, g^i)$, and if $i$ is odd while $j$ or $k$ is even (or if $i$ is even while $j$ and $k$ are both odd), then the adversary knows that the fourth element of the tuple must be a random group element, not $g^{jk}$.
    This gives the adversary a significant advantage over random guessing, so the DDH assumption does not hold.

    It is possible to work around this problem by constructing a prime-order subgroup of $\mathbb{Z}_p^*$; for example, the Digital Signature Algorithm (DSA) does this.
    In this subgroup, the DDH assumption is believed to hold.
    However, a problem that remains is that the numbers have to be quite large in order to be secure: if we want the difficulty of computing the discrete logarithm to be similar to the difficulty of breaking a 128-bit symmetric cipher, then $p$ needs to be over 3,000 bits long.

\item In the elliptic curve (EC) group that we construct in \autoref{sec:group-construction}, the DDH assumption is believed to be true.
    Moreover, computing discrete logarithms in EC groups is believed to be harder than in subgroups of $\mathbb{Z}_p^*$ for the same size of numbers, so EC groups can use 256-bit numbers to achieve the same 128-bit security level as 3,000-bit $\mathbb{Z}_p^*$ groups.
    This means EC group elements take less space in the network packets, and EC algorithms are faster for a given security level.
    This is the main benefit of using elliptic curves for cryptography instead of RSA or $\mathbb{Z}_p^*$ subgroups.
\end{itemize}

In all of these cases, it is a conjecture, not a proven fact, that the DDH assumption holds for a group.
The fact that we have not yet found an efficient attack against these cryptosystems does not guarantee that such an attack does not exist.
However, it's the best we have for the time being.

% https://cr.yp.to/highspeed/naclcrypto-20090310.pdf says (without citation):
% "There are weak theorems along these lines, stating that (for typical elliptic curves) a reliable algorithm to solve the [computational] Diffie–Hellman problem can be converted into a discrete-logarithm algorithm costing about ten thousand times as much."

\subsection{Finite fields}\label{sec:fields}

Most of the computations behind elliptic curve cryptography take place in a \emph{finite field}.
Building upon the definition of an abelian group in \autoref{sec:groups}, a field is a set of elements $F$ along with two operators (addition $a + b$ and multiplication $a \cdot b$), with the following properties:
\begin{itemize}
    \item The set $F$ and the addition operator $+$ form an abelian group with identity element $0$.
        We denote the inverse of $a \in F$ in this group as $-a$.
        The subtraction operator $a - b$ is then shorthand for $a + (-b)$.
    \item The set $F \setminus \{0\}$ and the multiplication operator $\cdot$ form an abelian group with identity element $1$.
        (0 is excluded because it has no multiplicative inverse, i.e.\ there is no $a \in F$ such that $0 \cdot a = 1$.)
        We denote the inverse of $a \in F$ in this group as $a^{-1}$.
        The division operator $\frac{a}{b}$ is then shorthand for $a \cdot (b^{-1})$.
    \item The addition and multiplication operators satisfy the distributive law: $a \cdot (b + c) = (a \cdot b) + (a \cdot c)$.
\end{itemize}
The real numbers $\mathbb{R}$ along with the usual addition and multiplication operators form a field with an infinite set of elements, but we can also define a field where the set of elements $F$ is finite.
This is called a \emph{finite field} (\emph{Galois field}).

Curve25519 uses the finite field of integers modulo $p = 2^{255}-19$.
Like in \autoref{sec:groups}, this field has the elements $\mathbb{Z}_p = \{0, 1, \dots, p-1\}$, with the usual addition and multiplication operators on integers, followed by reduction modulo $p$.
The additive inverse of $a$ modulo $p$ is $-a = p - a$, which always exists.
We discuss multiplicative inverses in \autoref{sec:cyclic}.

In a field we can perform algebraic manipulation of expressions, such as solving equations, in much the same way as when working with the real numbers $\mathbb{R}$: addition, subtraction, multiplication and division all behave as expected.
Exponentiation is defined as repeated multiplication, like in~\eqref{eq:power}.
Note that in a finite field of integers, division modulo $p$ is shorthand for multiplying by the multiplicative inverse: $\frac{a}{b} = a \cdot (b^{-1})$.
Thus, the result of division is still an integer modulo $p$ (a field element), not a fraction.

\subsection{Cyclic groups and multiplicative inverses}\label{sec:cyclic}

Let $a \in E$ be an element of a finite group $E$ with operator $\bullet$ and identity element $e$.
Consider the set of powers of $a$, that is, $\{a^0, a^1, \dots\}$, where $a^0 = e$ and $a^k = a \bullet a \bullet \dots \bullet a$ means applying $a$ to itself $k$ times.
By the closure property, the result of $\bullet$ is always an element of the group, so the set of powers must be a subset of the group elements $E$.
When the group is finite, the set of powers must also be finite.

The set of powers of $a \in E$ is called the \emph{subgroup} of $E$ that is \emph{generated} by $a$.
(A subgroup is a subset of group elements such that the operator still satisfies the five group properties listed in \autoref{sec:groups}.)
The \emph{order} of group element $a$ is defined to be the number of elements in the subgroup generated by $a$ (similarly to the order of the group, which is the number of elements in the group).

In particular, one possibility is that $\{a^0, a^1, \dots\} = E$: that is, $a$ generates the whole group $E$, and so the order of $a$ is the same as the order of the group.
If such a group element $a$ exists, the group is called \emph{cyclic}, and $a$ is called a \emph{generator} of the group.
It is called ``cyclic'' because if you examine the sequence of group elements $a^0$, $a^1$, $a^2$, etc.\ then eventually that sequence must repeat (since the group is finite); in a cyclic group, that repetition cycle contains all of the group elements, so $a^0 = a^{|E|}$, $a^1 = a^{|E|+1}$, $a^2 = a^{|E|+2}$ and so on, where $|E|$ is the number of elements in $E$.

It can be shown that if the order of a group $|E|$ is a prime number, then that group is always cyclic.
A nice property of a cyclic group is that the generator gives us a one-to-one mapping between the integers modulo $|E|$ and the group elements $E$.
Thus, if we choose an integer $k \in [0,\, |E|-1]$ uniformly at random and compute $a^k$, the result is a group element chosen uniformly at random~-- i.e.\ every group element is equally likely to be picked with probability $\frac{1}{|E|}$.
This fact is used in various cryptographic protocols.

In a finite cyclic group with generator $a$ and identity element $e$ we have $e = a^0 = a^{|E|} = a \bullet a^{|E|-1}$, so therefore $a^{|E|-1}$ must be the inverse element of $a$.
In general, for any group element $a$ with order $k$ we have $a^k = e$.

A similar rule applies to $\mathbb{Z}_p^*$, the multiplicative group of integers modulo $p$.
If $p$ is a prime, this group has order $p-1$ since 0 is not an element of the group.
For any $a \in \{1, \dots, p-1\}$, the multiplicative inverse of $a$ modulo $p$ is $a^{-1} = a^{p-2}$ (like before, the exponent is the group order minus 1).
This follows from Fermat's little theorem,\footnote{Not to be confused with Fermat's last theorem~-- same Fermat, different theorem.} which states that $a^{p-1} \equiv 1 \pmod{p}$ when $p$ is prime and $a \not\equiv 0 \pmod{p}$.
Since $a^{p-1} = a \cdot a^{p-2}$ we have that $a^{p-2}$ is the multiplicative inverse of $a$ modulo $p$.
We will use this fact in \autoref{sec:inverse} to compute inverses.

It is also possible to compute multiplicative inverses using the extended Euclid's algorithm.
However, this approach is generally not constant-time, whereas the approach using Fermat's little theorem is easy to make constant-time.

\subsection{The cofactor and small subgroups}\label{sec:cofactor}

In \autoref{sec:group-construction} we will define a group using the Curve25519 elliptic curve.
This group has order $hq$, where $h=8$ and $q = 2^{252} + 27742317777372353535851937790883648493$ is a prime number.
$q$ is only slightly larger than $2^{252}$, as we can see when written in hexadecimal: $q = \verb|0x1000000000000000000000000000000014def9dea2f79cd65812631a5cf5d3ed|$.
The parameters of Curve25519 are specifically chosen such that the order of the group is the product of a small integer $h$ (which is called the \emph{cofactor}, in this case 8), and a prime $q$ that is slightly greater than a large power of two~\cite{Bernstein:2006kw}.

Lagrange's theorem states that if a group $E$ has a subgroup $E'$, then the order of $E$ is divisible by the order of $E'$.
Since the set of powers of a group element generates a subgroup, this means the order of any group element must be a factor of the order of the group.
Therefore, each Curve25519 group element must have order either $1$, $2$, $4$, $8$, $q$, $2q$, $4q$, or $8q$: those are all of the factors of $8q$, and thus all of the possible orders of group elements.

The group would be simpler if it had a prime order (i.e.\ if the cofactor was $h=1$), since then all group elements would have order either $1$ or $q$.
However, elliptic curve groups using Montgomery curves such as Curve25519 (see \autoref{sec:curve-arithmetic}) always have a cofactor that is a multiple of 4.
Since Montgomery curves have other advantages, a design decision of Curve25519 was to accept the cofactor of 8, even though it makes the group more complicated to use safely~\cite{Hamburg:2015}.

For purposes of Diffie-Hellman (\autoref{sec:diffie-hellman}), Curve25519 uses a group element with order $q$ as generator $g$ (base point); since the subgroup generated by this element has prime order, it is cyclic.
However, if Alice is malicious, instead of sending group element $g^k$ to Bob, she could send a group element $s$ with small order, say order 8.
When Bob then computes $s^j$, where $j$ is Bob's private key, the result is one of only 8 possible group elements, since $s$ generates a subgroup of order 8, and so $s^a = s^{a+8} = s^{a+16} = \dots$.
Based on how Bob decrypts the message, Alice can use brute force to detect which of these 8 possible group elements Bob obtained, and thus Alice can determine the three least-significant bits of Bob's private key.
This is known as a \emph{small subgroup confinement attack}.

One way of preventing this attack is to \emph{validate public keys}~\cite{Antipa:2003}: on receiving a public key $s$, the recipient first checks that $s$ is indeed an element of the group, and is not the identity element.
Moreover, to verify that $s$ has order $q$, the recipient checks whether $s^q = e$ where $e$ is the identity element of the group.
Alternatively, the recipient could check that $s^h \ne e$ where $h$ is the cofactor, which works because $s^h = e$ whenever the order of $s$ is less than $q$.

X25519 does not perform public key validation, and uses a different approach to prevent small subgroup confinement attacks: it ensures that the exponent is always a multiple of the cofactor $h=8$.
Thus, if an attacker sends a group element $s$ with order less than $q$, the result of $s^{hj}$ will always be the identity element, regardless of the private key $j$, and so the adversary learns nothing about the private key.
When the correct generator $g$ with order $q$ is used, and $j \in [0,\, q-1]$ is uniformly distributed, the distribution of $g^{hj}$ is the same as the uniform distribution of $g^j$, so the extra factor of $h$ in the exponent is harmless.

Here is a proof sketch to show that the factor of $h$ does not change the distribution.
Let $g$ be a generator of a subgroup of prime order $q$, and let $g^a$ be any element of that subgroup, where $a \in [0,\, q-1]$ is uniformly distributed.
Assume $h$ is not a multiple of $q$, so $\mathrm{gcd}(h, q) = 1$.
Then the congruence equation $iq \equiv -a \pmod{h}$ has exactly one solution $i \in [0,\, h-1]$.
Let $i$ be that solution, so $iq + a \equiv 0 \pmod{h}$, so $iq + a$ is a multiple of $h$.
Moreover, since $0 \le i \le h-1$ and $0 \le a \le q-1$ we have $0 \le iq + a \le hq - 1$, so there exists exactly one $j \in [0,\, q-1]$ such that $hj = iq + a$.
Since the subgroup generated by $g$ is cyclic, we have $g^{q} = g^0$, and thus $g^{iq+a} = g^a$.
Therefore, for every $a \in [0,\, q-1]$ there exists a unique $j \in [0,\, q-1]$ such that $g^a = g^{hj}$, and vice versa.
Hence, the probability of generating $g^{hj}$ is the same as the probability of generating $g^a$; since the probability distribution is uniform, that probability is $\frac{1}{q}$.

\section{Finite field arithmetic}\label{sec:field-arithmetic}

Before we can implement elliptic curve operations, we first have to implement arithmetic operators (addition, subtraction, multiplication, and division) for the underlying finite field.
In the case of Curve25519 this is the field of integers modulo the prime $p = 2^{255} - 19$, as defined in \autoref{sec:fields}.

Most programming languages do not have built-in support for such large numbers; moreover, a general-purpose implementation of big numbers might not be suitable for cryptographic purposes, because the running time and memory access patterns of an operation may depend on the values of its inputs.
Such variations in timing and memory access can be exploited by \emph{side-channel attacks} to potentially leak secrets to an adversary.

The implementation analysed in this paper includes its own implementation of field arithmetic, which takes care to use \emph{constant-time} algorithms whose running time and memory access patterns do not depend on the input values.
The algorithms only rely on standard arithmetic and bit operators in C, which always take the same time to execute.

\subsection{Addition and subtraction}\label{sec:add-subtract}

We use two representations for integers modulo $p = 2^{255}-19$: a 32-element array of 8-bit values (bytes), and a 16-element array of 16-bit values.
The 32-byte representation is used for input and output, while the 16-element representation is used internally by the arithmetic operators.
In both cases, a little-endian order is used, i.e.\ the first element of an array contains the least significant bits, and the last element contains the most significant bits.

\autoref{code:arithmetic} shows the implementation of addition, subtraction, and multiplication modulo $p$.
The \verb|field_elem| datatype, defined on line~3, is used for the 16-element number representation.
Even though each element initially holds just 16 bits, it is declared as a 16-element array of 64-bit signed integers in order to simplify the following computations.

We can think of a 16-element array $(a_0, a_1, \dots, a_{15})$ as representing a number $a$ by multiplying each element with the appropriate power of 2:
\[ a = a_0 2^0 + a_1 2^{16} + a_2 2^{32} + \dots + a_{15} 2^{240} \]
This expression is still well-defined even if individual elements $a_i$ lie outside of the range $[0,\, 2^{16}-1]$.

\begin{listing}
\begin{minted}[linenos]{c}
typedef unsigned char u8;
typedef long long i64;
typedef i64 field_elem[16];

static void unpack25519(field_elem out, const u8 *in)
{
  int i;
  for (i = 0; i < 16; ++i) out[i] = in[2*i] + ((i64) in[2*i + 1] << 8);
  out[15] &= 0x7fff;
}

static void carry25519(field_elem elem)
{
  int i;
  i64 carry;
  for (i = 0; i < 16; ++i) {
    carry = elem[i] >> 16;
    elem[i] -= carry << 16;
    if (i < 15) elem[i + 1] += carry; else elem[0] += 38 * carry;
  }
}

static void fadd(field_elem out, const field_elem a, const field_elem b) /* out = a + b */
{
  int i;
  for (i = 0; i < 16; ++i) out[i] = a[i] + b[i];
}

static void fsub(field_elem out, const field_elem a, const field_elem b) /* out = a - b */
{
  int i;
  for (i = 0; i < 16; ++i) out[i] = a[i] - b[i];
}

static void fmul(field_elem out, const field_elem a, const field_elem b) /* out = a * b */
{
  i64 i, j, product[31];
  for (i = 0; i < 31; ++i) product[i] = 0;
  for (i = 0; i < 16; ++i) {
    for (j = 0; j < 16; ++j) product[i+j] += a[i] * b[j];
  }
  for (i = 0; i < 15; ++i) product[i] += 38 * product[i + 16];
  for (i = 0; i < 16; ++i) out[i] = product[i];
  carry25519(out);
  carry25519(out);
}
\end{minted}
\caption{Field arithmetic modulo $p = 2^{255} - 19$: addition, subtraction, and multiplication.}\label{code:arithmetic}
\end{listing}

We start with the \verb|unpack25519| function on lines~5--10 of \autoref{code:arithmetic}, which converts a number (a $\mathbb{Z}_p$ field element) from the byte array representation to the \verb|field_elem| representation.
The loop takes two adjacent bytes, \verb|in[2*i]| and \verb|in[2*i + 1]|, and combines them into a 16-bit value by shifting the second byte left by 8~bits and then adding them.
On line 9, it forces the most significant bit (the 255th bit) to be zero, since our numbers are always less than $2^{255}$.
Strictly speaking, this function allows the value to be within the range $[0,\, 2^{255} - 1]$, including the values $\{2^{255} - 19,\, \dots,\, 2^{255} - 1\}$ that are not reduced modulo $p$, but this does not do any harm, since the functions that take the \verb|field_elem| type as input handle these numbers correctly.

The \verb|fadd| function on lines~23--27 of \autoref{code:arithmetic} adds two field elements in \verb|field_elem| form, and similarly the \verb|fsub| function on lines~29--33 subtracts two field elements.
These functions are straightforward: they just add or subtract each of the 16 elements separately.
\begin{align}
    a + b &= (a_0 2^0 + a_1 2^{16} + a_2 2^{32} + \dots + a_{15} 2^{240}) + (b_0 2^0 + b_1 2^{16} + b_2 2^{32} + \dots + b_{15} 2^{240}) \nonumber\\
    &= (a_0 + b_0)\, 2^0 + (a_1 + b_1)\, 2^{16} + (a_2 + b_2)\, 2^{32} + \dots + (a_{15} + b_{15})\, 2^{240} \\[6pt]
    a - b &= (a_0 2^0 + a_1 2^{16} + a_2 2^{32} + \dots + a_{15} 2^{240}) - (b_0 2^0 + b_1 2^{16} + b_2 2^{32} + \dots + b_{15} 2^{240}) \nonumber\\
    &= (a_0 - b_0)\, 2^0 + (a_1 - b_1)\, 2^{16} + (a_2 - b_2)\, 2^{32} + \dots + (a_{15} - b_{15})\, 2^{240}
\end{align}

Since the \verb|field_elem| type uses 64-bit signed integers for each of the 16 elements, these addition or subtraction operations don't overflow or underflow, and we don't have to worry about propagating carry bits.
However, we have to keep in mind that each of the elements may now be greater than $2^{16}$, or negative.

\subsection{Multiplication modulo $p$}\label{sec:multiplication}

The \verb|fmul| function on lines~35--46 multiplies two numbers in \verb|field_elem| form.
\verb|product| is a 31-element array of 64-bit integers, initialised to zero.
On lines~39--41 we iterate in a nested loop over each of the elements of the input numbers \verb|a| and \verb|b|, and adding their product to the appropriate elements of \verb|product|.
This is equivalent to how we do long multiplication with pen and paper:
\begin{align}
    \mathit{product} = a \cdot b &= (a_0 2^0 + a_1 2^{16} + a_2 2^{32} + \dots + a_{15} 2^{240}) \cdot (b_0 2^0 + b_1 2^{16} + b_2 2^{32} + \dots + b_{15} 2^{240}) \nonumber\\
    &= a_0 b_0 2^{0+0} + a_1 b_0 2^{16+0} + \dots + a_{15} b_0 2^{240+0} + a_0 b_1 2^{0+16} + a_1 b_1 2^{16+16} + \dots + a_{15} b_{15} 2^{240+240} \nonumber\\
    &= a_0 b_0 2^0 + (a_1 b_0 + a_0 b_1)\, 2^{16} + (a_2 b_0 + a_1 b_1 + a_0 b_2)\, 2^{32} + \dots + a_{15} b_{15} 2^{480} \label{eq:multiplication}
\end{align}
\verb|product| now contains the product of \verb|a| and \verb|b| (the product of two 255-bit numbers is a 510-bit number).

In order to bring the 31-element array \verb|product| into a 16-element \verb|field_elem| form, we can reduce modulo $p$, as explained in \autoref{sec:modular-arithmetic}.
However, for performance reasons, we do not fully reduce modulo $p$ in the multiplication function \verb|fmul|.
Instead, we reduce modulo $2p = 2\,(2^{255} - 19) = 2^{256} - 38$ on line~42 of \autoref{code:arithmetic}.
This is valid because reducing modulo a multiple of $p$ preserves all of the necessary information; we can later reduce modulo $p$ and the end result will be the same as if we had not performed the intermediate reduction modulo $2p$.

\verb|for (i = 0; i < 15; ++i) product[i] += 38 * product[i+16]| \emph{almost} reduces \verb|product| modulo $2p$ because $2^{256} = 2p + 38$:
\begin{align}
    \mathit{product} &= t_0 2^0 + t_1 2^{16} + t_2 2^{32} + \dots + t_{15} 2^{240} + t_{16} 2^{256} + t_{17} 2^{272} \dots + t_{30} 2^{480} \nonumber\\
    &= t_0 2^0 + t_1 2^{16} + t_2 2^{32} + \dots + t_{15} 2^{240} + t_{16} 2^0\, (2p + 38) + t_{17} 2^{16}\, (2p + 38) + \dots + t_{30} 2^{224}\, (2p + 38) \nonumber\\
    &\equiv t_0 2^0 + t_1 2^{16} + t_2 2^{32} + \dots + t_{15} 2^{240} + 38\, t_{16} 2^0 + 38\, t_{17} 2^{16} \dots + 38\, t_{30} 2^{224} \pmod{2p} \nonumber\\
    &= (t_0 + 38\, t_{16})\, 2^0 + (t_1 + 38\, t_{17})\, 2^{16} + \dots + (t_{14} + 38\, t_{30})\, 2^{224} + t_{15} 2^{240} \label{eq:reduce-2p}
\end{align}
After this step the result is in elements \verb|product[0]| to \verb|product[15]|, and we ignore \verb|product[16]| to \verb|product[30]|.
This computation is ``almost'' a reduction modulo $2p$ because, although the number now fits in the \verb|field_elem| type with 16 elements, we have not yet done anything to bring each element within the $[0,\, 2^{16}-1]$ range, so the number as a whole is not fully reduced modulo $2p$.

Before we continue, we should check that the calculation so far does not overflow the 64-bit variables we are using (signed integer overflow is undefined behaviour in C, so it is important to be sure that it cannot happen).
When we come to use the addition, subtraction, and multiplication functions in \autoref{sec:ladder-optimised}, it will turn out that the result of a multiplication undergoes at most one addition or subtraction before becoming the input to another multiplication.
Thus, if we assume that a multiplication returns a \verb|field_elem| number in which each element is in the range $[0,\, 2^{16}]$, then after one addition or subtraction, we can assume that each of the elements $a_i$, $b_i$ of the inputs to a multiplication is in the range $[-2^{16},\, 2^{17}]$.
The greatest number of terms being added to one element in equation~\eqref{eq:multiplication} is for $t_{15}$:
\[ t_{15} = a_{15} b_0 + a_{14} b_1 + a_{13} b_2 + \dots + a_1 b_{14} + a_0 b_{15} \]

Each of the products $a_i b_j$ is in the range $[-2^{33},\, 2^{34}]$, so therefore the sum of 16 of these terms must be in the range $[-2^{37},\, 2^{38}]$.
Reduction modulo $2p$ in equation~\eqref{eq:reduce-2p} may further multiply an element by a factor of 38; over-approximating 38 as $2^6$ gives us a final range of $[-2^{43},\, 2^{44}]$.
Thus, we can conclude that 64-bit arithmetic gives us plenty of headroom to complete the calculation without overflowing.\footnote{Incidentally, the JavaScript port of TweetNaCl uses double-precision floating-point arithmetic, since JavaScript does not support 64-bit integer arithmetic.
IEEE 754 double-precision floating point numbers use an exact representation for integers in the range $[-2^{53}+1,\, 2^{53}-1]$; as we can see from this analysis, that precision is also sufficient to perform this multiplication algorithm correctly.}

Finally, in order to bring the elements back into the range $[0,\, 2^{16}-1]$, the \verb|fmul| function first copies \verb|product[0]| to \verb|product[15]| into the output variable \verb|out|, and then calls the \verb|carry25519| function twice (lines~43--45).

The \verb|carry25519| function (lines~12--21 of \autoref{code:arithmetic}) cleans up a value of type \verb|field_elem| by \emph{almost} bringing all of the elements within the $[0,\, 2^{16}-1]$ range.
I say ``almost'' because there are edge cases in which some elements exceed that range after one or two calls to \verb|carry25519|.
In order to be certain that all of the elements are within $[0,\, 2^{16}-1]$, the function needs to be called \emph{three} times.
However, after two calls to \verb|carry25519|, that range can only be exceeded by a small amount; for the purposes of the multiplication function, two calls are sufficient, since we just need to ensure the element values are small enough that they do not cause overflow when they become the input to subsequent multiplications.

% Here's an example value that requires three calls to carry25519(val) before all elements are within [0, 0xffff]:
% field_elem val = {0x10, 0xffff, 0xffff, 0xffff, 0xffff, 0xffff, 0xffff, 0xffff, 0xffff, 0xffff, 0xffff, 0xffff, 0xffff, 0xffff, 0xffff, 0xfffffffff};

\verb|carry25519| iterates over the 16 elements of the \verb|field_elem| number \verb|elem|, performing the following for each:
\begin{enumerate}
\item Line~17 computes \verb|carry = elem[i] >> 16;| selecting all bits that are greater than the low-order 16 bits.

\item Line~18 updates \verb|elem[i] -= carry << 16;| which subtracts the carry bits from \verb|elem[i]|, leaving its value within the range $[0,\, 2^{16}-1]$ (even if the case where \verb|elem[i]| was previously negative).

\item On line~19, the carry bits are added to the next element, except when \verb|elem[i]| is already the last element.
    If we are at the last element (\verb|i == 15|), the carry is multiplied by 38 and added to the first element, performing reduction modulo $2p$ as previously in equation~\eqref{eq:reduce-2p}.
    This operation is constant-time despite the presence of an \verb|if| statement, since it only depends on the variable \verb|i|, which is not secret.
\end{enumerate}

If it was not for the last element's carry wrapping around to \verb|elem[0]|, the \verb|carry25519| function would leave all elements within $[0,\, 2^{16}-1]$.
However, this carry can cause \verb|elem[0]| to be greater than $2^{16}$, or even negative.
A second call to \verb|carry25519| can fix this; however, if elements \verb|elem[1]| to \verb|elem[15]| are close to \verb|0xffff|, the carry bits from \verb|elem[0]| can cause a cascade of carries on the second call, resulting in a further carry from \verb|elem[15]| to \verb|elem[0]|, causing \verb|elem[0]| to exceed \verb|0xffff| \emph{again}.
On a third call to \verb|carry25519|, such a carry cascade is no longer possible, since the values of the middle elements are now zero, and so the third call finally brings all elements within the range $[0,\, 2^{16}-1]$.

In any case, the number of times \verb|carry25519| is called must be constant (not dependent on whether or not there is a carry), since otherwise the function would no longer be constant-time.

\begin{listing}
\begin{minted}[linenos]{c}
typedef unsigned char u8;
typedef long long i64;
typedef i64 field_elem[16];

static void finverse(field_elem out, const field_elem in)
{
  field_elem c;
  int i;
  for (i = 0; i < 16; ++i) c[i] = in[i];
  for (i = 253; i >= 0; i--) {
    fmul(c, c, c);
    if (i != 2 && i != 4) fmul(c, c, in);
  }
  for (i = 0; i < 16; ++i) out[i] = c[i];
}

static void swap25519(field_elem p, field_elem q, int bit)
{
  i64 t, i, c = ~(bit - 1);
  for (i = 0; i < 16; ++i) {
    t = c & (p[i] ^ q[i]);
    p[i] ^= t;
    q[i] ^= t;
  }
}

static void pack25519(u8 *out, const field_elem in)
{
  int i, j, carry;
  field_elem m, t;
  for (i = 0; i < 16; ++i) t[i] = in[i];
  carry25519(t); carry25519(t); carry25519(t);
  for (j = 0; j < 2; ++j) {
    m[0] = t[0] - 0xffed;
    for(i = 1; i < 15; i++) {
      m[i] = t[i] - 0xffff - ((m[i - 1] >> 16) & 1);
      m[i - 1] &= 0xffff;
    }
    m[15] = t[15] - 0x7fff - ((m[14] >> 16) & 1);
    carry = (m[15] >> 16) & 1;
    m[14] &= 0xffff;
    swap25519(t, m, 1 - carry);
  }
  for (i = 0; i < 16; ++i) {
    out[2*i] = t[i] & 0xff;
    out[2*i + 1] = t[i] >> 8;
  }
}
\end{minted}
\caption{Multiplicative inverse, and converting numbers from internal representation to byte arrays.}\label{code:pack25519}
\end{listing}

\subsection{Computing the multiplicative inverse}\label{sec:inverse}

Now that we have defined addition, subtraction, and multiplication, the missing arithmetic operation on field elements is division modulo $p=2^{255}-19$.
As explained in \autoref{sec:cyclic}, we perform division $\frac{b}{a}$ by computing the multiplicative inverse of the denominator, $a^{-1}$, and then multiplying that inverse with the numerator $b$.

The \verb|finverse| function on lines~5--15 of \autoref{code:pack25519} computes the multiplicative inverse of its input \verb|in|, writing the result to the output variable \verb|out|.
Both input and output are in \verb|field_elem| form.
The computation of the inverse uses Fermat's little theorem as per \autoref{sec:cyclic}, by computing $a^{-1} \equiv a^{p-2} \pmod{p}$.
The exponential $a^{p-2}$ can be computed using the \emph{square-and-multiply} method, which is based on the following recursive relations:
\[ a^{2i} = a^i \cdot a^i \qquad\text{and}\qquad a^{2i+1} = a \cdot a^i \cdot a^i. \]
That is, we first compute $a^i$ recursively, and then square $a^i$ to obtain $a^{2i}$.
If the exponent is odd, we additionally multiply the result with another copy of $a$ to obtain $a^{2i+1}$.

$p-2 = 2^{255}-21 = \texttt{0x7fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffeb}$ is a constant, so \verb|finverse| hard-codes the pattern of squarings and multiplications.
All of the bits of $p-2$ are 1, except for bits 2 and 4, which are 0 (where bit 0 is the least-significant bit).
The loop in the \verb|finverse| function counts down from the most-significant to the least-significant bit, squaring the current value \verb|c| using the \verb|fmul| function for each bit, and also multiplying \verb|c| with the input value \verb|in| for each bit that is 1.
Even though $p-2$ consists of 255 bits, the loop is able to start at bit 253 and save one iteration by initialising \verb|c| to \verb|in| instead of 1.
At the end, \verb|c| is copied to the output variable \verb|out|.

\subsection{Converting back to a byte array}\label{sec:pack}

The final aspect of finite field arithmetic that we need to complete is to convert from the \verb|field_elem| representation of a number back to the byte array representation, which is done by the \verb|pack25519| function on lines~27--48 of \autoref{code:pack25519}.
This function performs the inverse of the \verb|unpack25519| function discussed in \autoref{sec:add-subtract}.
In the process, we will also reduce the number modulo $p$, which ensures that every distinct element in the field of integers modulo $p$ is represented by a unique byte string.
This will be essential when we later want to use such a field element to derive an encryption key.

First, we explain the helper function \verb|swap25519(p, q, bit)| on lines~17--25 of \autoref{code:pack25519}.
If \verb|bit| is 1, this function swaps the content of parameters \verb|p| and \verb|q| (both in \verb|field_elem| representation), and it does nothing if \verb|bit| is 0.
Since \verb|bit| may be part of a secret value, this function cannot use a simple \verb|if| statement, since that would not be constant-time.
Instead, it must ensure that it always performs exactly the same operations, regardless of the value of \verb|bit|.

\verb|swap25519| first sets \verb|c = ~(bit - 1)|, which equals 0 if \verb|bit == 0|, and \verb|0xffff...| if \verb|bit == 1|.
Next it iterates over each of the 16 elements of the number, and computes \verb|t = c & (p[i] ^ q[i])| for index \verb|i|, which equals 0 if \verb|bit == 0|, and \verb|p[i] ^ q[i]| if \verb|bit == 1|.
The operation \verb|p[i] ^= t| thus has no effect if \verb|bit == 0|, and it sets \verb|p[i] = p[i] ^ (p[i] ^ q[i]) = q[i]| if \verb|bit == 1|.
Likewise, \verb|q[i]| is set to \verb|p[i]| if \verb|bit == 1|.

Next, we turn to \verb|pack25519|.
This function first copies the input value \verb|in| to \verb|t|, and then calls \verb|carry25519| on it three times.
As discussed in \autoref{sec:multiplication}, this ensures that all of the 16 elements of \verb|t| fall within the range $[0,\, 2^{16}-1]$.
Thus, we have a 256-bit number that is \emph{not quite} reduced modulo $2p$, since it may fall within the entire range $[0,\, 2^{256}-1]$ (i.e.\ it may be slightly greater than $2p$).

To reduce that number $t$ modulo $p$, notice that there are three possibilities: either $0 \le t < p$ (i.e.\ $t$ is already reduced modulo $p$), or $p \le t < 2p$ (i.e.\ we need to subtract $p$ from $t$ to reduce it modulo $p$), or $2p \le t < 2^{256}$ (i.e.\ we need to subtract $2p$ from $t$).
However, for the function to be constant-time, we cannot simply detect which of these three is the case, and subtract the appropriate multiple of $p$.
Instead, we have to calculate both $t-p$ and $t-2p$, and then use a constant-time algorithm to choose which of the three values $\{t,\, t-p,\, t-2p\}$ to return.
This is done by the loop \verb|for (j = 0; j < 2; ++j)| on lines~33--43.

Most of the loop body is taken up by the logic to subtract $p$ from \verb|t|, and write the result to \verb|m|.
Rather than reusing the earlier \verb|fsub| function to subtract, followed by repeated \verb|carry25519| calls to handle the carry, this function implements its own carry handling.

On line~34, \verb|m[0] = t[0] - 0xffed;| subtracts from \verb|t[0]| the least-significant 16 bits of $p$, which are \verb|0xffed|.
This may result in a negative number, but the subsequent \verb|m[0] &= 0xffff;| on line~37 puts it back in the range $[0,\, 2^{16}-1]$, after first taking the carry bit \verb|(m[0] >> 16) & 1| and subtracting it from \verb|m[1]| (line~36).
We then repeat this for the next 14 elements of \verb|t|, except that we subtract \verb|0xffff| (the middle bits of $p$) instead of \verb|0xffed|.
For \verb|t[15]| we subtract \verb|0x7fff| (the most-significant 16 bits of $p$), place the carry bit in variable \verb|carry|, and otherwise perform the same steps.

The carry bit of the result of subtracting $t-p$ is 1 if the result is negative, and 0 if it is zero or positive.
If this bit is 1, \verb|1 - carry| on line~42 equals 0, so \verb|swap25519| does nothing, so the variable \verb|t| is left unchanged and the negative result is discarded.
If this bit is 0, \verb|1 - carry| equals 1, so \verb|swap25519| swaps the values of \verb|t| and \verb|m|, i.e.\ it updates \verb|t| to be the non-negative value $t-p$.
Thus, the subtraction of $p$ takes effect only if the result is non-negative.
After two iterations of this loop, $t$ is guaranteed to be in the range $[0,\, p-1]$.

Finally, on lines~44--47 the value of \verb|t| is copied to the output byte array \verb|out|.
Each of the 16-bit elements is split into two bytes and assigned to two adjacent elements of the byte array.
This completes the cycle, starting with input values that arrive as byte arrays, which may be manipulated in \verb|field_elem| form through field arithmetic operations, with the result eventually converted back to a byte array.

\section{Elliptic curve arithmetic}\label{sec:curve-arithmetic}

Curve25519 uses the curve
\begin{equation}\label{eq:curve}
y^2 = x^3 + A x^2 + x
\end{equation}
which is known as a \emph{Montgomery curve}, with parameter $A = 486662$.
We will use equation~\eqref{eq:curve} as our starting point; a justification for the use of this equation and the choice of $A$ appear in the Curve25519 paper \cite{Bernstein:2006kw}.
Our derivations work for any $A^2 \ne 4$; this restriction ensures the curve has the required shape.
Some other curve equations are also used for elliptic curve cryptography, such as the \emph{short Weierstrass} equation
\begin{equation}
y^2 = x^3 + Ax + B
\end{equation}
but in this paper we focus on Montgomery curves.

\begin{figure}
% Points for first plot are computed as follows:
% a = -1.9
% xp = 0.1; yp = -sqrt(xp*xp*xp + a*xp*xp + xp)
% xq = 0.8; yq =  sqrt(xq*xq*xq + a*xq*xq + xq)
% m = (yq - yp) / (xq - xp)
% xa = -0.1; ya = yp - m * (xp - xa)
% xb =  2.0; yb = ya + m * (xb - xa)
% xc = m*m - a - xp - xq; yc = yp + m * (xc - xp)
\begin{tikzpicture}[scale=3.0]
\node at (0.2,-1.5) {(a)};
\draw [->] (-0.1,0) -- (2.1,0) node[right] {$x$};
\draw [->] (0,-1.6) -- (0,1.6) node[above] {$y$};
\draw [color=blue] plot[id=pos,domain=0:2,samples=100] function{ sqrt(x**3 - 1.9*x**2 + x)};
\draw [color=blue] plot[id=neg,domain=0:2,samples=100] function{-sqrt(x**3 - 1.9*x**2 + x)};
\draw [color=red] (0.1,-0.28636) circle [radius=1pt] node[below,outer sep=5pt] {$P$};
\draw [color=red] (0.8, 0.30984) circle [radius=1pt] node[above,outer sep=5pt] {$Q$};
\draw [color=red] (1.7254, 1.0980) circle [radius=1pt] node[below,outer sep=5pt] {$R$};
\draw [color=red] (-0.1,-0.45669) -- (2.0,1.331887391631657);
\end{tikzpicture}
\hfill
% Points for the second plot are computed as follows:
% a = -1.9
% xp = 0.3; yp = sqrt(xp*xp*xp + a*xp*xp + xp)
% m = (3*xp*xp + 2*a*xp + 1) / (2*yp)
% xa = -0.1; ya = yp - m * (xp - xa)
% xb =  2.0; yb = ya + m * (xb - xa)
% xc = m*m - a - 2*xp; yc = yp + m * (xc - xp)
\begin{tikzpicture}[scale=3.0]
\node at (0.2,-1.5) {(b)};
\draw [->] (-0.1,0) -- (2.1,0) node[right] {$x$};
\draw [->] (0,-1.6) -- (0,1.6) node[above] {$y$};
\draw [color=blue] plot[id=pos,domain=0:2,samples=100] function{ sqrt(x**3 - 1.9*x**2 + x)};
\draw [color=blue] plot[id=neg,domain=0:2,samples=100] function{-sqrt(x**3 - 1.9*x**2 + x)};
\draw [color=red] (0.25,0.38324) circle [radius=1pt] node [above,outer sep=5pt] {$P=Q$};
\draw [color=red] (1.49601,0.76932) circle [radius=1pt] node [below,outer sep=5pt] {$R$};
\draw [color=red] (-0.1,0.27479) -- (2.0,0.92549);
\end{tikzpicture}
\caption{(a) If we draw a line through two points $P=(x_P,y_P)$ and $Q=(x_Q,y_Q)$ on an elliptic curve, where $x_P \neq x_Q$, then that line intersects the curve again in a third point $R$. (b) Generalising to $P=Q$, we draw a tangent to the curve at $P$, which intersects the curve at $R$.}
\Description{Plot of the elliptic curve equation over real numbers}
\label{fig:curve}
\end{figure}

\subsection{Straight line intersecting the elliptic curve}\label{sec:straight-line}

We say that a point $P = (x, y)$ lies on the curve if $(x, y)$ is a solution of equation~\eqref{eq:curve}.
\autoref{fig:curve} shows an example of such a curve.
Notice that the curve has reflection symmetry around the $x$ axis; more formally, if $(x, y)$ is on the curve then $(x, -y)$ is also on the curve.
This is the case because the variable $y$ appears only in the $y^2$ term in~\eqref{eq:curve}.

For now we will treat the coordinates $x$ and $y$ as real numbers.
In Curve25519 they are actually integers modulo $2^{255} - 19$, but we will do the following derivation using real numbers as it is easier to visualise, and allows us to use some calculus.
It turns out that the end result works with any field.

If we have two points $P=(x_P,y_P)$ and $Q=(x_Q,y_Q)$ that both lie on the curve, we can draw a straight line through those points.
If we assume that $x_P \neq x_Q$, then that straight line intersects the curve at some third point $R$, as shown in \autoref{fig:curve}(a).
We will show shortly that this third point $R$ always exists.
This straight line is defined by the equation
\begin{equation}
y = \lambda x + c \quad\text{ where the slope is }\quad
\lambda = \frac{y_Q - y_P}{x_Q - x_P} \quad\text{ and the $y$-intercept is }\quad c = y_P - \lambda\,x_P. \label{eq:line}
\end{equation}

If $x_P=x_Q$ we distinguish three possibilities: either $y_P=y_Q=0$, or $y_P=y_Q \ne 0$, or $y_P=-y_Q \ne 0$.
Consider first the case where $y_P=-y_Q \ne 0$, shown in \autoref{fig:vertical}: if we draw a straight line through the two points, that line is vertical, and there is no third intersection point.
We will return to this case, and the $y_P=y_Q=0$ case, in \autoref{sec:group-construction}.

Next, consider the case where $y_P=y_Q \ne 0$, i.e. $P=Q$ and the points are not on the $x$ axis.
In this case we can still define a straight line through $P$ and $Q$, and we choose the slope of the line such that it is a tangent to the curve (i.e.\ it touches the curve at $P$ without crossing it).
This is the natural generalisation of the slope $\lambda = (y_Q - y_P)/(x_Q - x_P)$ in the limit as the distance between $P$ and $Q$ tends to zero.

To compute the slope $\lambda$ of this tangent, we can calculate the derivative of the curve equation~\eqref{eq:curve} using the chain rule:
\begin{align}
y^2 &= x^3 + A x^2 + x \quad\iff\quad y = \pm\sqrt{x^3 + A x^2 + x}\\[5pt]
\lambda = \frac{\mathrm{d}y}{\mathrm{d}x} &= \pm\frac{3x^2 + 2Ax + 1}{2\sqrt{x^3 + Ax^2 + x}}
= \pm\frac{3x^2 + 2Ax + 1}{2|y|}
= \frac{3x^2 + 2Ax + 1}{2y} \label{eq:derivative}
\end{align}
% TODO this handling of the sign could be a bit more rigorous
The sign of $\lambda$ in equation~\eqref{eq:derivative} works out correctly for both positive and negative $y$.
The tangent is then defined by $y = \lambda x + c$ as before, and it exists whenever $y \ne 0$.
If $y=0$, the tangent is vertical, and we handle this as part of the case $y_P=-y_Q$ in \autoref{sec:group-construction}.

\begin{figure}
\centering
% a = -1.9; xp = 0.6; yp = -sqrt(xp*xp*xp + a*xp*xp + xp)
\begin{tikzpicture}[scale=3.0]
\draw [->] (-0.1,0) -- (2.1,0) node[right] {$x$};
\draw [->] (0,-1.0) -- (0,1.0) node[above] {$y$};
\draw [color=blue] plot[id=pos2,domain=0:1.6,samples=100] function{ sqrt(x**3 - 1.9*x**2 + x)};
\draw [color=blue] plot[id=neg2,domain=0:1.6,samples=100] function{-sqrt(x**3 - 1.9*x**2 + x)};
\draw [color=red] (0.6,-0.36332) circle [radius=1pt] node[below right,outer sep=5pt] {$P$};
\draw [color=red] (0.6, 0.36332) circle [radius=1pt] node[above right,outer sep=5pt] {$Q$};
\draw [color=red] (0.6,-1.0) -- (0.6,1.0);
\end{tikzpicture}
\caption{If $x_P=x_Q$ and $y_P=-y_Q$, the line going through the two points is vertical.}
\Description{Plot of the elliptic curve equation intersected by a vertical line}
\label{fig:vertical}
\end{figure}

In the cases where the straight line is not vertical, we work out the third point $R$ at which the line intersects the elliptic curve.
We do this by substituting the line equation~\eqref{eq:line} into the curve equation~\eqref{eq:curve}:
\begin{equation}
(\lambda x + c)^2 = x^3 + Ax^2 + x \quad\iff\quad x^3 + (A - \lambda^2)\, x^2 + (1 - 2\lambda c)\, x - c^2 = 0 \label{eq:intersect}
\end{equation}
The roots of the polynomial~\eqref{eq:intersect} are the $x$ coordinates of the points at which the line intersects the curve.
Since we know that $P$ and $Q$ lie on both the line and the curve, $x_P$ and $x_Q$ must be roots of~\eqref{eq:intersect}, and so we can divide~\eqref{eq:intersect} by the polynomial $(x - x_P)(x - x_Q) = x^2 - (x_P + x_Q)\,x + x_P x_Q$.
This works even if $x_P=x_Q$, for the following reason: in the case of $P=Q$ we chose the line to be a tangent to the curve; therefore, the derivative of \eqref{eq:intersect} is zero at $x_P$; therefore, $x_P$ is a double root of \eqref{eq:intersect} and we can divide it by $x - x_P$ twice.
Performing the polynomial division:
\begin{equation*}\arraycolsep=1pt\def\arraystretch{1.3}
\begin{array}{ll}
& \hspace{60pt} x + A - \lambda^2 + x_P + x_Q \\
x^2 - (x_P + x_Q)\,x + x_P x_Q \;&
\overline{\smash{\Big)}\; x^3 + (A - \lambda^2)\, x^2 \hspace{42pt} + (1 - 2\lambda c)\, x \hspace{37pt} - c^2} \\
& \hspace{7pt}\underline{x^3 - (x_P + x_Q)\, x^2 \hspace{35pt} + x_P x_Q x} \\
& \hspace{26pt}(A - \lambda^2 + x_P + x_Q)\, x^2 + (1 - 2\lambda c - x_P x_Q)\, x - c^2 \\
& \hspace{26pt}(A - \lambda^2 + x_P + x_Q)\, x^2 - (A - \lambda^2 + x_P + x_Q)\,(x_P + x_Q)\, x \\
& \hspace{26pt}\underline{\hspace{105pt} +\, (A - \lambda^2 + x_P + x_Q)\,x_P x_Q \hspace{30pt}} \\
& \hspace{116pt}\dots
\end{array}
\end{equation*}
The polynomial division produces an extremely ugly expression as remainder, but fortunately we do not need to compute it, since we know that it must be zero.
From the quotient $x + A - \lambda^2 + x_P + x_Q$ we obtain the $x$ coordinate of the third intersection point $R$:
\begin{equation}
x_R = \lambda^2 - A - x_P - x_Q \label{eq:xR}
\end{equation}
and we obtain the $y$ coordinate by substituting $x_R$ into the line equation~\eqref{eq:line}:
\begin{equation}
y_R = \lambda\,x_R + c = \lambda\,x_R + y_P - \lambda\,x_P = y_P + \lambda\,(x_R - x_P) \label{eq:yR}
\end{equation}
Since $(x_R, y_R)$ is defined whenever $\lambda$ exists, we know that the third intersection point $R$ exists whenever the straight line is not vertical.

\begin{listing}
\begin{minted}{python}
# The finite field of integers modulo p (GF is short for Galois Field)
field = GF(2^255 - 19)

# EllipticCurve(field, [a1, a2, a3, a4, a5]) constructs an elliptic curve over the
# given field, with curve equation y^2 + a1*x*y + a3*y = x^3 + a2*x^2 + a4*x + a5.
# We choose a1 = 0, a2 = 486662, a3 = 0, a4 = 1, a5 = 0 to give us the Montgomery
# curve equation y^2 = x^3 + 486662 * x^2 + x.
E = EllipticCurve(field, [0, 486662, 0, 1, 0])

# Check the order (cardinality) of the group defined by that curve
q = 2^252 + 27742317777372353535851937790883648493
q.is_prime() # returns True
E.cardinality() == 8 * q # returns True

# Define the base point (generator) g to be the point with x coordinate = 9,
# and check the order of that point
base = 9
g = [field(base), sqrt(field(base^3 + 486662 * base^2 + base))] # [x, y] coordinates
q * E(g) # returns (0 : 1 : 0), which is the point at infinity
# This indicates that point g has order q in the elliptic curve group E.
\end{minted}
\caption{SageMath code to compute the order of the Curve25519 group and the base point.}\label{code:group-order}
\end{listing}

\subsection{Constructing a group}\label{sec:group-construction}

We will now use the results from the last section to construct a group.
The set of group elements is the set of points on the elliptic curve~\eqref{eq:curve}, plus one special element $\infty$ that we call the \emph{point at infinity}:
\begin{equation}
E = \{(x,y) \mid y^2 = x^3 + A x^2 + x\} \;\cup\; \{\infty\}
\end{equation}
The group has an infinite number of elements when the $x$ and $y$ coordinates are real numbers, but when they are integers modulo $p$, the group order is finite.
For $x, y \in \mathbb{Z}_p$ there are $p^2$ possible $(x, y)$ pairs, and only some of them are solutions of the curve equation.
The exact number of solutions depends on the curve equation, the parameter $A$, and the size of the underlying field.
Algorithms for counting the number of curve points are presented in textbooks~\cite{Blake:1999,Cohen:2006}.
In the case of Curve25519 with $p=2^{255}-19$ and $A = 486662$ we have $|E| = 8 \cdot (2^{252} + 27742317777372353535851937790883648493)$ as discussed in \autoref{sec:cofactor}.
We can use SageMath to check this is correct, as shown in \autoref{code:group-order}.

The point at infinity has no coordinates, and its purpose is to deal with vertical lines.
When two different points have the same $x$ coordinate and we draw a vertical line through them, like in \autoref{fig:vertical}, we define the point at infinity to be the third point at which the line ``intersects the curve''.
We can imagine this point as lying infinitely far up the $y$ axis, and all vertical lines intersect that point.

The point at infinity will also serve as the identity element of our group.
That is, we define the following to be true:
\begin{equation}
P \bullet \infty \;=\; \infty \bullet P \;=\; P \quad\text{ for all } P \in E. \label{eq:law-identity}
\end{equation}
In particular, $\infty\bullet\infty=\infty$.
Moreover, for any point $P = (x_P, y_P)$ on the curve, we define the \emph{inverse} to be $P^{-1} = (x_P, -y_P)$, i.e.\ the point obtained by mirroring $P$ with respect to the $x$ axis.
By definition, the inverse satisfies the following property:
\begin{equation}
P \bullet P^{-1} \;=\; P^{-1} \bullet P \;=\; \infty \quad\text{ for all } P \in E. \label{eq:law-inverse}
\end{equation}
We also define that $\infty^{-1} = \infty$.

Intuitively, we can think of the operator $P \bullet Q$ as combining two points $P$ and $Q$ by drawing a straight line through them and finding a third point on the curve.
To fully define the operator $\bullet$, we start with the following idea: for any three points $P, Q, R \in E$, if those points lie on the same line, then we have
\begin{equation}
P \bullet Q \bullet R = \infty.
\end{equation}
We can achieve this by defining $P \bullet Q = R^{-1}$, and then $(P \bullet Q) \bullet R = R^{-1} \bullet R = \infty$.
That is, given two curve points $P$ and $Q$, we can draw a straight line through those points, find the third point at which that line intersects the curve, and then invert that point by negating its $y$ coordinate.
The point obtained in this way is $P \bullet Q$.

Using our results~\eqref{eq:xR} and~\eqref{eq:yR} for the coordinates of the third intersection point, along with equations~\eqref{eq:line} and~\eqref{eq:derivative} for the slope $\lambda$, we can now define $P_1 \bullet P_2$ for any two points $P_1$ and $P_2$ on the curve with $P_1 \neq P_2^{-1}$:
\begin{align}
P_1 \bullet P_2 = (x_1, y_1) \bullet (x_2, y_2) &= (x_3, y_3) \quad\text{where}\nonumber\\
x_3 = \lambda^2 - A - x_1 - x_2 &= \begin{dcases}
\left(\frac{y_2 - y_1}{x_2 - x_1}\right)^2 - A - x_1 - x_2 & \text{if } x_1 \neq x_2 \\
\left(\frac{3x_1^2 + 2Ax_1 + 1}{2y_1}\right)^2 - A - 2x_1 & \text{if } x_1 = x_2
\end{dcases}\label{eq:law-x}\\
y_3 = -(y_1 + \lambda\,(x_3 - x_1)) &= \lambda\,(x_1 - \lambda^2 + A + x_1 + x_2) - y_1 =
\lambda\,(2x_1 + x_2 + A) - \lambda^3 - y_1 =\label{eq:law-y}\\
&= \begin{dcases}
\frac{(2x_1 + x_2 + A) (y_2 - y_1)}{x_2 - x_1} - \left(\frac{y_2 - y_1}{x_2 - x_1}\right)^3 - y_1 & \text{if } x_1 \neq x_2 \\
\frac{(2x_1 + x_2 + A) (3x_1^2 + 2Ax_1 + 1)}{2y_1} - \left(\frac{3x_1^2 + 2Ax_1 + 1}{2y_1}\right)^3 - y_1 & \text{if } x_1 = x_2
\end{dcases}\nonumber
\end{align}

The formulas~\eqref{eq:law-x} and~\eqref{eq:law-y}, along with definitions~\eqref{eq:law-identity} and~\eqref{eq:law-inverse}, form the \emph{group law} for Montgomery curves.
These definitions may seem somewhat arbitrary, but $\bullet$ has to be defined this way in order to obtain a group.
For example, if we did not invert the third intersection point of the line, the resulting operation would not form a group.

To prove that our definitions form an abelian group, we need to show that the five properties of \autoref{sec:groups} hold:
\begin{itemize}
\item The closure property holds by definition, since the point $(x_3, y_3)$ defined by~\eqref{eq:law-x} and~\eqref{eq:law-y} lies on the curve, and the result of the group operation in~\eqref{eq:law-identity} and~\eqref{eq:law-inverse} is also an element of $E$.
\item The identity element $\infty$ exists and has the required behaviour according to definition~\eqref{eq:law-identity}.
\item The inverse element $P^{-1}$ exists for every $P \in E$ and has the required behaviour according to definition~\eqref{eq:law-inverse}.
\item To show that the commutativity property holds, consider several cases.
If $P = \infty$ and/or $Q = \infty$, we have $P \bullet Q = Q \bullet P$ due to~\eqref{eq:law-identity}.
If $P = Q^{-1}$, we have $P \bullet Q = Q \bullet P$ due to~\eqref{eq:law-inverse}.
Finally, if $P \neq \infty$, $Q \neq \infty$ and $P \neq Q^{-1}$, consider the straight line through curve points $P$ and $Q$.
We show that the line through $P$ and $Q$ is the same as the line through $Q$ and $P$, and thus the third intersection point of this line with the curve must be the same.
If $P=Q$, the two lines are trivially the same according to~\eqref{eq:derivative}.
If $P \neq Q$, we examine the line equation~\eqref{eq:line}:
\begin{align}
y = \lambda x + c = \lambda\,(x - x_P) + y_P &= \frac{y_Q - y_P}{x_Q - x_P}\,(x - x_P) + y_P \label{eq:commutative1}\\[5pt]
& = \frac{-(y_P - y_Q)}{-(x_P - x_Q)}\,(x - x_P) + \frac{y_P\,(x_P - x_Q)}{x_P - x_Q} \nonumber\\[5pt]
& = \frac{(y_P - y_Q)\,x - x_P y_P + x_P y_Q + x_P y_P - x_Q y_P}{x_P - x_Q} \nonumber\\[5pt]
& = \frac{(y_P - y_Q)\,x + x_P y_Q - x_Q y_P + (x_Q y_Q - x_Q y_Q)}{x_P - x_Q} \nonumber\\[5pt]
& = \frac{(y_P - y_Q)\,x - (y_P - y_Q)\,x_Q + (x_P - x_Q)\,y_Q}{x_P - x_Q} \nonumber\\[5pt]
& = \frac{y_P - y_Q}{x_P - x_Q}\,(x - x_Q) + y_Q \label{eq:commutative2}
\end{align}
The expressions~\eqref{eq:commutative1} and~\eqref{eq:commutative2} are equal except for swapping $P$ and $Q$.
Thus, we have $P \bullet Q = Q \bullet P$ for all $P, Q \in E$.
\end{itemize}

The final step is to show that $\bullet$ is associative: $(a \bullet b) \bullet c = a \bullet (b \bullet c)$.
Unfortunately, proving associativity is rather more complex than the other properties: proofs of this property involve either some advanced mathematics, or the use of a computer algebra software package~\cite{Friedl:2017js,Fujii:2017eb}.
We will therefore skip the proof of this property.

Instead, to check our result, we can look up Montgomery curves in the \emph{Explicit Formulas Database} (EFD)~\cite{MontgomeryEFD}, which lists the group law as follows:
\begin{verbatim}
name Montgomery curves
parameter a
parameter b
coordinate x
coordinate y
satisfying b y^2 = x^3 + a x^2 + x
addition x = b (y2-y1)^2/(x2-x1)^2-a-x1-x2
addition y = (2 x1+x2+a) (y2-y1)/(x2-x1)-b (y2-y1)^3/(x2-x1)^3-y1
doubling x = b (3 x1^2+2 a x1+1)^2/(2 b y1)^2-a-x1-x1
doubling y = (2 x1+x1+a) (3 x1^2+2 a x1+1)/(2 b y1)-b (3 x1^2+2 a x1+1)^3/(2 b y1)^3-y1
\end{verbatim}
This database uses a slightly more general form $B y^2 = x^3 + A x^2 + x$ with an additional parameter $B$.
We can see that with $B=1$, the formulas in the database equal our formulas~\eqref{eq:law-x} and~\eqref{eq:law-y}.
The formulas in the EFD are checked using SageMath; we will not repeat those checks here.

\paragraph{A note on notation.}
In the literature on elliptic curves, the group operation $\bullet$ is traditionally written as $+$, the inverse of $P$ is written as $-P$, combining two different points $P$ and $Q$ using the group operation $P+Q$ is called \emph{point addition}, and combining a point $P$ with itself $P+P=2P$ is known as \emph{point doubling}.
On the other hand, in the literature on cryptographic protocols, the group operation is traditionally written as multiplication $\cdot$, the inverse of $P$ is written as $P^{-1}$, and combining a group element with itself is written as $P \cdot P = P^2$.
In this paper we use $\bullet$ as the group operation on \emph{elliptic curve group elements} $E$, in order to avoid confusion with the addition and multiplication of individual \emph{field elements} (i.e.\ integers modulo $p$), which is used in the formulas above.

\begin{figure}
\centering
\input{jumping}
\caption{Using the group operator to repeatedly combine a curve point $P$ with itself. Each application of the operator can be visualised as drawing a straight line through $P$ and $P^i$, finding the third point where this line intersects the curve, and mirroring that point with respect to the $x$ axis to obtain $P^{i+1}$. The result is a sequence of points that ``jump around'' in a pseudorandom manner.}
\Description{Six plots of an elliptic curve, each showing how two points are combined with the group operator to produce a third point. On each plot, the first input point is a constant starting point $P$, and the other input point is the output point of the previous plot. The sequence of points jumps around the curve with no discernible pattern.}
\label{fig:jumping}
\end{figure}

\subsection{Elliptic-curve Diffie-Hellman}\label{sec:ecdh}

Now that we have constructed a group, we can use this group for cryptographic protocols.
In particular, we can use the Curve25519 group to implement the X25519 Diffie-Hellman key exchange function.

For a group element $P \in E$ and a non-negative integer $k$ we define the repeated application of the group operator to $P$ as before:
\begin{equation}
P^k = \underbrace{P \bullet P \bullet \cdots \bullet P}_\text{$k$ times}
\end{equation}
We show in \autoref{sec:ladder} how to compute $P^k$ efficiently, even for large $k$.
This operation is known as \emph{scalar multiplication} (where \emph{scalar} refers to the fact that $k$ is an integer, not a group element).

We can visualise the sequence $P$, $P^2$, $P^3$, {\dots} as repeatedly drawing a line through points $P$ and $P^i$, as shown in \autoref{fig:curve}, finding a third intersection point of this line, and mirroring it with respect to the $x$ axis to obtain point $P^{i+1}$.
The effect, intuitively speaking, is a sequence of points that ``jump around'' the curve in a complicated pattern that is difficult to predict, as illustrated in \autoref{fig:jumping}.
This complicated pattern is what makes the group suitable for cryptography.
In particular, it is believed that the Decisional Diffie-Hellman assumption (see \autoref{sec:cdh-ddh}) is true in this group.

The best known algorithms for discrete logarithms in this group, such as Pollard's rho algorithm~\cite{Pollard:1978do}, boil down to essentially trying lots of values of $k$ until we find a result that matches the input $P^k$.
This algorithm takes approximately $O(\sqrt{k})$ time to find $k$.
Thus, if we choose $k$ to be $n$ bits long, the time taken is $O(2^{n/2})$.
X25519 chooses $n=251$ (less than 255 because four bits are set to constant values), making the difficulty of computing the discrete logarithm similar to the difficulty of breaking a 128-bit symmetric cipher.

\begin{listing}
\begin{minted}[linenos]{c}
typedef unsigned char u8;
typedef unsigned long long u64;
extern void randombytes(u8 *, u64);
static const u8 _9[32] = {9};

void scalarmult_base(u8 *out, const u8 *scalar)
{ 
  scalarmult(out, scalar, _9);
}

void generate_keypair(u8 *pk, u8 *sk)
{
  randombytes(sk, 32);
  scalarmult_base(pk, sk);
}

void x25519(u8 *out, const u8 *pk, const u8 *sk)
{
  scalarmult(out, sk, pk);
}
\end{minted}
\caption{Using the \texttt{scalarmult} function to implement Diffie-Hellman.}\label{code:diffie-hellman}
\end{listing}

\autoref{code:diffie-hellman} shows how to implement Diffie-Hellman.
The \verb|scalarmult(out, scalar, point)| function takes three arguments: \verb|point| is the input group element $P$, \verb|scalar| is the scalar exponent, and \verb|out| is a pointer to memory where the output $P^\mathit{scalar}$ will be written.
\verb|point|, \verb|scalar| and \verb|out| are all 255-bit numbers, encoded as arrays of 32 bytes.
In fact, \verb|point| and \verb|out| are not full group elements, but only the $x$ coordinate of points on the curve; we will see in \autoref{sec:ladder} why we can leave out the $y$ coordinate.
We will see the implementation of \verb|scalarmult| in \autoref{code:scalarmult}.

\verb|scalarmult_base(out, scalar)| performs scalar multiplication using a fixed group element \verb|_9|, which is a curve point whose $x$ coordinate equals 9.
This point is chosen because its order is a large prime, as explained in \autoref{sec:cofactor}.
\autoref{code:group-order} shows how we can check the order of this point using SageMath.
The result is again returned in \verb|out|.

\verb|generate_keypair(pk, sk)| generates a new keypair, where the private key is written to \verb|sk| and the public key is written to \verb|pk|.
The private key consists of 32 bytes (256 bits) drawn from a secure source of uniform random numbers.
The public key is obtained from scalar multiplication of \verb|sk| with the fixed base point in \verb|scalarmult_base|.

\verb|x25519(out, pk, sk)| is called by both the sender and the recipient of a message.
If called by the sender, \verb|pk| is the recipient's public key and \verb|sk| is the random integer generated by the sender (Alice's $k$ in the example in \autoref{sec:diffie-hellman}).
If called by the recipient, \verb|pk| is the group element sent along with the message ($g^k$ in the example of \autoref{sec:diffie-hellman}) and \verb|sk| is the recipient's private key.
In either case, computing the scalar product of the group element and the secret integer produces the shared secret, which is written to \verb|out|.
The shared secret can then be used to initialise a symmetric cipher to encrypt the actual message, but this is beyond the scope of X25519, so we do not discuss it further in this paper.

\subsection{The Montgomery ladder}\label{sec:ladder}

The Montgomery ladder~\cite{Bernstein:2017fm,Costello:2018,Montgomery:1987fz} is the algorithm used by X25519 to efficiently perform scalar multiplication.
The function $L(P, i)$ takes a group element $P \ne \infty$ and a non-negative integer $i$, and it returns a pair of group elements $(P^i, P^{i+1})$ computed using the group operator $\bullet$:
\begin{align}
L(P,\, 0) &= (\infty, P) \label{eq:ladder}\\
L(P,\, 2i) &= (P_i \bullet P_i,\, P_i \bullet P_{i+1}) & \text{ where } L(P, i) = (P_i, P_{i+1}) \text{ and } i>0 \nonumber\\
L(P,\, 2i+1) &= (P_i \bullet P_{i+1},\, P_{i+1} \bullet P_{i+1}) & \text{ where } L(P, i) = (P_i, P_{i+1}) \text{ and } i \ge 0 \nonumber
\end{align}
Here $P^0 = \infty$ because $\infty$ is the identity element of the group.
The second argument is halved (rounding down, i.e.\ shifting right by one bit) on each recursive call, resulting in $\lfloor\log_2 i\rfloor + 1$ recursive calls to compute $L(P, i)$ (i.e.\ one call per bit of $i$).
In practice, we can use a loop instead of recursion, and in each iteration of the loop we examine one bit of $i$, starting with the most significant bit.
(\autoref{code:scalarmult} on page~\pageref{code:scalarmult} shows our implementation of the Montgomery ladder; lines~19 to~43 contain the main loop that iterates over the bits of the integer.)
At each loop iteration we perform two group operations:
\begin{itemize}
\item If the bit is zero (i.e.\ the $2i$ case), we combine $P_i$ with itself to produce $P^i \bullet P^i = P^{2i}$, and we combine $P_i$ with $P_{i+1}$ to produce $P^i \bullet P^{i+1} = P^{2i+1}$.
\item If the bit is one (i.e.\ the $2i+1$ case), we combine $P_i$ with $P_{i+1}$ to produce $P^i \bullet P^{i+1} = P^{2i+1}$, and we combine $P_{i+1}$ with itself to produce $P^{i+1} \bullet P^{i+1} = P^{2i+2}$.
\end{itemize}

The reason we return two group elements rather than just one is that, as we shall see shortly, there is a particularly efficient formula for computing $P^i \bullet P^{i+1} = P^{2i+1}$ given $P$, $P^i$ and $P^{i+1}$, which is faster than directly using the group law in~\eqref{eq:law-x}, \eqref{eq:law-y}.

In X25519 we need to execute this loop 255 times (the integer in the scalar multiplication function is 256 bits, but we set the topmost bit to always be zero, hence only 255 iterations are needed).
As this is the most time-consuming part of the algorithm, we now examine how to perform these group operations as fast as possible.

\paragraph{Using projective coordinates.}

First of all, notice that equations~\eqref{eq:law-x} and~\eqref{eq:law-y} contain fractions.
If we have to perform division on each iteration of the loop, the multiplicative inverse operation would become the slowest part of the algorithm.
To save time, we can represent coordinates as fractions: $x = X/Z$ and $y = Y/Z$, where $X$, $Y$ and $Z$ are integers.
(These are known as \emph{projective coordinates}, whereas the $(x, y)$ coordinates we have been using so far are called \emph{affine coordinates}.)
At each loop iteration we calculate the numerator and denominator for the coordinates separately, without dividing, and we perform the actual division only once, at the end after we have finished the loop.

\paragraph{Projective formulas for point doubling.}

Let's first derive optimised formulas for combining a group element with itself:
$P_{2i} = (x_{2i}, y_{2i}) = P_i \bullet P_i = (x, y) \bullet (x, y)$.
Using the expression in~\eqref{eq:law-x}:
\begingroup\allowdisplaybreaks
\begin{align}
x_{2i} &= \frac{(3x^2 + 2Ax + 1)^2}{4y^2} - A - 2x \nonumber\\[5pt]
&= \frac{(3x^2 + 2Ax + 1)^2}{4\,(x^3 + Ax^2 + x)} - A - 2x 
    \quad\text{ since } (x, y) \text { is on the curve } y^2 = x^3 + Ax^2 + x \nonumber\\[5pt]
&= \frac{(3x^2 + 2Ax + 1)^2 - 4\,(x^3 + Ax^2 + x)(2x + A)}{4\,(x^3 + Ax^2 + x)} \nonumber\\[5pt]
&= \frac{9x^4 + 12Ax^3 + (4A^2 + 6)\,x^2 + 4Ax + 1 -4\,(2x^4 + 3Ax^3 + (A^2 + 2)\,x^2 + Ax)}{4\,(x^3 + Ax^2 + x)} \nonumber\\[5pt]
&= \frac{x^4 -2x^2 + 1}{4\,(x^3 + Ax^2 + x)} 
    \;=\; \frac{\frac{X^4}{Z^4} - \frac{2X^2}{Z^2} + 1}{4\,\left(\frac{X^3}{Z^3} + \frac{AX^2}{Z^2} + \frac{X}{Z}\right)}
    \quad\text{ using projective coordinates } x=\frac{X}{Z} \label{eq:alt-doubling}\\[5pt]
&= \frac{\frac{1}{Z^4}\,(X^4 - 2X^2 Z^2 + Z^4)}{\frac{4}{Z^3}\,(X^3 + AX^2 Z + X Z^2)}
    \;=\; \frac{X^4 - 2X^2 Z^2 + Z^4}{4XZ\,(X^2 + AX Z + Z^2)}
    \;=\; \frac{(X^2 - Z^2)^2}{4XZ\,(X^2 + AX Z + Z^2)} \nonumber
\end{align}
\endgroup
Thus, we obtain the following projective formulas for point doubling:
\begin{equation}
\left(\frac{X_i}{Z_i}, \frac{Y_i}{Z_i}\right) \bullet \left(\frac{X_i}{Z_i}, \frac{Y_i}{Z_i}\right) =
\left(\frac{X_{2i}}{Z_{2i}}, \frac{Y_{2i}}{Z_{2i}}\right) \quad\text{where}\quad
\begin{array}{l}
    X_{2i} = (X_i^2 - Z_i^2)^2 \\[5pt]
    Z_{2i} = 4X_i Z_i\,(X_i^2 + AX_i Z_i + Z_i^2)
\end{array}\label{eq:projective-double}
\end{equation}

Note that that the formulas for $X_{2i}$ and $Z_{2i}$ do not use the $Y$ coordinate anywhere.
This means that we can avoid computing any $Y$ coordinates in the first place, and we don't even need to derive an expression for $Y_{2i}$.
Next, we will derive formulas for point addition that also avoid using any $Y$ coordinates.

\paragraph{Projective formulas for point addition.}

We now derive formulas for the group operation
$P_{2i+1} = (x_{2i+1}, y_{2i+1}) = P_i \bullet P_{i+1} = (x_1, y_1) \bullet (x_2, y_2)$.
We assume that $P_i \ne P_{i+1}$ (because we know that $P_{i+1} = P^{i+1} = P^i \bullet P = P_i \bullet P$ and we are assuming that $P \ne \infty$), and we also assume that $P_i^{-1} \ne P_{i+1}$ (in this case, $P_{2i+1} = \infty$).
Therefore we can assume $x_1 \neq x_2$.
Taking equation~\eqref{eq:law-x} as our starting point:

\begin{align}
x_{2i+1} &= \left(\frac{y_2 - y_1}{x_2 - x_1}\right)^2 - A - x_1 - x_2 \nonumber\\[5pt]
&= \frac{y_2^2 - 2y_1 y_2 + y_1^2 - (A + x_1 + x_2)\,(x_2 - x_1)^2}{(x_2 - x_1)^2} \nonumber\\[5pt]
&= \frac{x_2^3 + Ax_2^2 + x_2 + x_1^3 + Ax_1^2 + x_1 - 2y_1 y_2}{(x_2 - x_1)^2} \nonumber\\
    &\quad - \frac{Ax_2^2 - 2Ax_1 x_2 + Ax_1^2 + x_1 x_2^2 - 2 x_1^2 x_2 + x_1^3 + x_2^3 - 2x_1 x_2^2 + x_1^2 x_2}{(x_2 - x_1)^2} \nonumber\\[5pt]
&= \frac{x_1 + x_2 + x_1^2 x_2 + x_1 x_2^2 + 2A x_1 x_2 - 2y_1 y_2}{(x_2 - x_1)^2} \nonumber\\[5pt]
&= \frac{(x_1 + x_2)\,(1 + x_1 x_2) + 2A x_1 x_2 - 2y_1 y_2}{(x_2 - x_1)^2} \label{eq:add-x}
\end{align}

Next, we use the fact that $P_{i+1} = P_i \bullet P$.
Because every element of the group has an inverse, we have $P_i^{-1} \bullet P_{i+1} = P_i^{-1} \bullet P_i \bullet P = P$.
Let $P = (x_P, y_P)$, $P_i = (x_1, y_1)$, and $P_{i+1} = (x_2, y_2)$.
Because $P_i^{-1} = (x_1, -y_1)$ we have
\begin{align*}
P = (x_P, y_P) = P_i^{-1} \bullet P_{i+1} = (x_1, -y_1) \bullet (x_2, y_2) \quad\Longrightarrow\quad
x_P = \frac{(x_1 + x_2)\,(1 + x_1 x_2) + 2A x_1 x_2 + 2y_1 y_2}{(x_2 - x_1)^2}
\end{align*}
That is, $x_P$ equals the expression~\eqref{eq:add-x} with $y_1$ inverted.
To clear the remaining occurrences of $y_1$ and $y_2$ from~\eqref{eq:add-x}, without introducing square roots, we multiply $x_{2i+1}$ and $x_P$ (derivation from~\cite{Bernstein:2017fm}):
\begin{align*}
x_P x_{2i+1}\,(x_2 - x_1)^4 &=
    ((x_1 + x_2)\,(1 + x_1 x_2) + 2A x_1 x_2 + 2y_1 y_2)\,((x_1 + x_2)\,(1 + x_1 x_2) + 2A x_1 x_2 - 2y_1 y_2) \\
&= ((x_1 + x_2)\,(1 + x_1 x_2) + 2A x_1 x_2)^2 - (2y_1 y_2)^2 \\
&= ((x_1 + x_2)\,(1 + x_1 x_2) + 2A x_1 x_2)^2 - 4\,(x_1^3 + Ax_1^2 + x_1)\,(x_2^3 + Ax_2^2 + x_2) \\
&= (x_1 + x_2)^2\, (1 + x_1 x_2)^2 + 4Ax_1 x_2\,(x_1 + x_2)\,(1 + x_1 x_2) + 4A^2 x_1^2 x_2^2 \\
    &\quad -4\,(x_1^3 + x_1)\,(x_2^3 + x_2) - 4Ax_1^2\,(x_2^3 + x_2) - 4Ax_2^2\,(x_1^3 + x_1) - 4A^2 x_1^2 x_2^2 \\
&= (x_1 + x_2)^2\, (1 + x_1 x_2)^2 + 4Ax_1 x_2\,(x_1 + x_2 + x_1^2 x_2 + x_1 x_2^2) \\
    &\quad -4\,(x_1^3 + x_1)\,(x_2^3 + x_2) - 4Ax_1 x_2\,(x_1 x_2^2 + x_1 + x_1^2 x_2 + x_2) \\
&= (x_1 + x_2)^2\, (1 + x_1 x_2)^2 - 4\,(x_1^3 + x_1)\,(x_2^3 + x_2) \\
&= (x_1^2 + 2x_1 x_2 + x_2^2)\,(1 + 2x_1 x_2 + x_1^2 x_2^2) - 4\,(x_1^3 x_2^3 + x_1 x_2^3 + x_1^3 x_2 + x_1 x_2) \\
&= x_1^2 + 2x_1 x_2 + x_2^2 + 2x_1^3 x_2 + 4x_1^2 x_2^2 + 2x_1 x_2^3 + x_1^4 x_2^2 + 2x_1^3 x_2^3 + x_1^2 x_2^4 \\
    &\quad - 4x_1^3 x_2^3 - 4x_1 x_2^3 - 4x_1^3 x_2 - 4x_1 x_2 \\
&= x_1^2 - 2x_1 x_2 + x_2^2 - 2x_1^3 x_2 + 4x_1^2 x_2^2 - 2x_1 x_2^3 + x_1^4 x_2^2 - 2x_1^3 x_2^3 + x_1^2 x_2^4 \\
&= (x_2 - x_1)^2 - 2x_1 x_2\,(x_2 - x_1)^2 + x_1^2 x_2^2\,(x_2 - x_1)^2 \\
&= (x_2 - x_1)^2\,(x_1 x_2 - 1)^2
\end{align*}

Hence, under the assumption that $x_P \ne 0$, we obtain
\begin{align}
x_{2i+1} &= \frac{(x_1 x_2 - 1)^2}{x_P\,(x_2 - x_1)^2}
    = \frac{\left(\frac{X_1 X_2}{Z_1 Z_2} - 1\right)^2}{\frac{X_P}{Z_P} \left(\frac{X_2}{Z_2} - \frac{X_1}{Z_1}\right)^2}
    \quad\text{where}\quad x_P = \frac{X_P}{Z_P},\; x_1 = \frac{X_1}{Z_1},\; x_2 = \frac{X_2}{Z_2} \nonumber\\[5pt]
&= \frac{Z_P \left(\frac{X_1^2 X_2^2}{Z_1^2 Z_2^2} - \frac{2X_1 X_2}{Z_1 Z_2} + 1\right)}{X_P \left(\frac{X_2^2}{Z_2^2} - \frac{2X_1 X_2}{Z_1 Z_2} + \frac{X_1^2}{Z_1^2}\right)}
= \frac{\frac{Z_P}{Z_1^2 Z_2^2} \left(X_1^2 X_2^2 - 2X_1 X_2 Z_1 Z_2 + Z_1^2 Z_2^2\right)}{\frac{X_P}{Z_1^2 Z_2^2} \left(X_2^2 Z_1^2 - 2X_1 X_2 Z_1 Z_2 + X_1^2 Z_2^2\right)} \nonumber\\[5pt]
    &= \frac{Z_P\,(X_1 X_2 - Z_1 Z_2)^2}{X_P\,(X_1 Z_2 - X_2 Z_1)^2} \label{eq:projective-add}
\end{align}
In X25519, the base point $P$ of the scalar multiplication $x_P = X_P/Z_P$ is given as an affine coordinate (i.e.\ not as a fraction), and $P \ne \infty$ so we can assume $Z_P=1$ and $X_P=x_P$.

Thus, we can compute one step of the Montgomery ladder using the formulas from~\eqref{eq:projective-double} and~\eqref{eq:projective-add}:
\begin{align}
X_{2i} &= (X_i^2 - Z_i^2)^2 &
X_{2i+1} &= (X_i X_{i+1} - Z_i Z_{i+1})^2 \label{eq:ladder-step}\\
Z_{2i} &= 4X_i Z_i\,(X_i^2 + AX_i Z_i + Z_i^2) &
Z_{2i+1} &= x_P\,(X_i Z_{i+1} - X_{i+1} Z_i)^2 \nonumber
\end{align}
These formulas never use the $y$ coordinate, allowing us to operate on the $x$ coordinate alone.
They take as input one bit of the scalar, the output from the previous step $(X_i, Z_i, X_{i+1}, Z_{i+1})$, as well as the base point $x$ coordinate $x_P$.
If the current bit is zero, they produce $(X_{2i}, Z_{2i}, X_{2i+1}, Z_{2i+1})$ as output, as shown in~\eqref{eq:ladder}.
If the current bit is one, they produce $(X_{2i+1}, Z_{2i+1}, X_{2i+2}, Z_{2i+2})$ as output, where $X_{2i+2}$ and $Z_{2i+2}$ are computed by applying the doubling formulas to $(X_{i+1}, Z_{i+1})$ instead of $(X_i, Z_i)$.

One desirable property of these formulas is that each step of the ladder performs exactly the same arithmetic operations, regardless of the input coordinates and the bits of the scalar, making the algorithm constant-time.

\subsection{Handling the point at infinity}\label{sec:handling-infinity}

In the derivation of the above formulas we have so far considered only points that are solutions to the curve equation, and ignored the point at infinity $\infty$.
It is time that we now address this issue.

The point at infinity cannot be represented in affine coordinates $(x, y)$ for any finite $x$, $y$.
However, a convenient feature of using projective coordinates is that we can represent the point at infinity as a fraction with a denominator of zero: we define the $x$ coordinate of $\infty$ to be $\frac{X}{0}$, i.e.\ $Z = 0$.
We do not allow $X$ and $Z$ to both be zero.
We can ignore the $y$ coordinate since our formulas do not use it.

Fortunately, our formulas~\eqref{eq:ladder-step} already handle the point at infinity correctly.
We demonstrate this by showing that they produce the required result if any of their inputs are $\infty$.
Moreover, we show that provided each input is valid, $(X, Z) \ne (0, 0)$, then the outputs will also be different from $(0, 0)$.
The following assumes that $x_P \ne 0$.

\begin{itemize}
    \item Let $Z_i=0$ and $X_i \ne 0$, so $P_i = \infty$.
        Then $Z_{2i}=0$ and $X_{2i} = X_i^4 \ne 0$, so $P_{2i} = P_i \bullet P_i = \infty\bullet\infty = \infty$ as required by~\eqref{eq:law-identity}.
    \item Let $Z_i \ne 0$. We consider two cases depending on the value of $X_i^3 + AX_i^2 Z_i + X_i Z_i^2$:
        \begin{enumerate}
            \item Assume that $X_i^3 + AX_i^2 Z_i + X_i Z_i^2 = 0$; hence $Z_{2i} = 0$.
                To prove that $X_{2i} \ne 0$, suppose to the contrary that $X_{2i}=0$; then $X_i^2 = Z_i^2$ so $Z_i = \pm X_i$.
                Substituting into $X_i^3 + AX_i^2 Z_i + X_i Z_i^2 = 0$ yields $X_i^3 \pm AX_i^3 + X_i^3 = 0$, so $AX_i^3 = \pm 2X_i^3$.
                Since $Z_i \ne 0$ we have $X_i \ne 0$, and hence $A = \pm 2$.
                However, this contradicts the assumption that $A^2 \ne 4$, stated at the beginning of \autoref{sec:curve-arithmetic}.
                Therefore we have $(X_{2i}, Z_{2i}) \ne (0, 0)$ as required.
            \item Assume that $X_i^3 + AX_i^2 Z_i + X_i Z_i^2 \ne 0$, which implies $X_i \ne 0$.
                Since $Z_i \ne 0$ we have $Z_{2i} \ne 0$, so we have $(X_{2i}, Z_{2i}) \ne (0, 0)$ as required.
        \end{enumerate}
    \item Let $Z_i \ne 0$, $Z_{i+1} \ne 0$, and $P_i$ has the same $x$ coordinate as $P_{i+1}$, i.e.\ $X_i/Z_i = X_{i+1}/Z_{i+1}$.
        This implies one of two situations: either $P_i = P_{i+1}$ or $P_i^{-1} = P_{i+1}$.
        The former is ruled out by our assumption that $P \ne \infty$, so we have $P_i^{-1} = P_{i+1}$ and require that $P_i \bullet P_{i+1} = \infty$ as per~\eqref{eq:law-inverse}.
        $X_i/Z_i = X_{i+1}/Z_{i+1}$ implies that $X_i Z_{i+1} = X_{i+1} Z_{i}$, so $Z_{2i+1} = 0$ as required.

        Next, we need to show that $X_{2i+1} \ne 0$.
        Suppose to the contrary that $X_{2i+1} = 0$, implying that $X_i X_{i+1} - Z_i Z_{i+1} = 0$.
        Taken together with the fact $X_i Z_{i+1} = X_{i+1} Z_{i}$ that we showed earlier, we have $X_i X_{i+1} - Z_i Z_{i+1} - X_i Z_{i+1} + X_{i+1} Z_{i} = (X_i + Z_i)\,(X_{i+1} - Z_{i+1}) = 0$.
        We now have two cases:
        \begin{enumerate}
            \item If $X_i + Z_i = 0$ then $X_i = -Z_i$ so $X_i/Z_i = -1$.
                Using assumption $X_i/Z_i = X_{i+1}/Z_{i+1}$ we have $X_{i+1}/Z_{i+1} = x_{i+1} = -1$, so the affine $x$ coordinate of $P_{i+1}$ equals $-1$.
            \item If $X_i + Z_i \ne 0$ then $X_{i+1} = Z_{i+1}$ so $X_{i+1}/Z_{i+1} = x_{i+1} = 1$, so the affine $x$ coordinate of $P_{i+1}$ equals $1$.
        \end{enumerate}
        In both cases, we use the point doubling expression~\eqref{eq:alt-doubling} to calculate the $x$ coordinate of $P_{i+1} \bullet P_{i+1}$, which is $(x_{i+1}^4 -2x_{i+1}^2 + 1)/(4x_{i+1}^3 + 4Ax_{i+1}^2 + 4x_{i+1}) = 0$ for $x_{i+1} = \pm 1$.
        Note that $P_{i+1} = P_i \bullet P$, so $P = P_i^{-1} \bullet P_{i+1} = P_{i+1} \bullet P_{i+1}$ due to our earlier observation that $P_i^{-1} = P_{i+1}$.
        Hence, the $x$ coordinate of $P$ equals zero, which contradicts our earlier assumption that $x_P \ne 0$.
        Thus we have $X_{2i+1} \ne 0$ as required.
    \item Let $Z_i \ne 0$, $Z_{i+1} \ne 0$, and $P_i$ has a different $x$ coordinate from $P_{i+1}$, i.e.\ $X_i/Z_i \ne X_{i+1}/Z_{i+1}$.
        Then $X_i Z_{i+1} \ne X_{i+1} Z_i$ so $Z_{2i+1} \ne 0$, so $P_{2i+1} \ne \infty$ as required.
    \item Let $Z_i=0$ and $X_i \ne 0$, so $P_i = \infty$.
        Since $P_{i+1} = P_i \bullet P = \infty \bullet P = P$ and $P \ne \infty$ we have $Z_{i+1} \ne 0$ and $X_{i+1}/Z_{i+1} = x_P$, so $X_{i+1} = x_P Z_{i+1}$.
        Hence, $X_{2i+1} = (X_i X_{i+1})^2 = x_P^2 X_i^2 Z_{i+1}^2$ and $Z_{2i+1} = x_P\,(X_i Z_{i+1})^2 \ne 0$.
        Thus, $X_{2i+1}/Z_{2i+1} = x_P^2 X_i^2 Z_{i+1}^2 / x_P X_i^2 Z_{i+1}^2 = x_P$ so $P_{2i+1} = P_i \bullet P_{i+1} = \infty \bullet P = P$ as required by~\eqref{eq:law-identity}.
    \item Let $Z_{i+1} = 0$ and $X_{i+1} \ne 0$, so $P_{i+1} = \infty$.
        Since $P_{i+1} = P_i \bullet P$ and $P \ne \infty$ we have $P_i = P^{-1}$ and $Z_i \ne 0$.
        The $x$ coordinate of $P^{-1}$ is the same as the $x$ coordinate of $P$, namely $x_P$, so $X_i/Z_i = x_P$, so $X_i = x_P Z_i$.
        Hence, similarly to the last case, we have $X_{2i+1} = (X_i X_{i+1})^2 = x_P^2 X_{i+1}^2 Z_i^2$ and $Z_{2i+1} = x_P\,(-X_{i+1} Z_i)^2 \ne 0$.
        Thus, $X_{2i+1}/Z_{2i+1} = x_P^2 X_{i+1}^2 Z_i^2 / x_P X_{i+1}^2 Z_i^2 = x_P$, which is consistent with $P_{2i+1} = P_i \bullet P_{i+1} = P^{-1} \bullet \infty = P^{-1}$ as required by~\eqref{eq:law-identity}.
\end{itemize}

These bullet points cover all possible cases, demonstrating that the formulas~\eqref{eq:ladder-step} correctly handle all group elements, including the point at infinity, without need for any special handling of edge cases.
That is good news because the lack of edge cases simplifies the implementation of the Montgomery ladder.
Moreover, it is easier to make the algorithm constant-time if every step of the ladder performs exactly the same arithmetic operations, independently of the values of its inputs.

\subsection{Optimising the Montgomery ladder step}\label{sec:ladder-optimised}

The formulas~\eqref{eq:ladder-step} are nice and simple, but if we compare them to the implementation of the Montgomery ladder in \autoref{code:scalarmult}, the two look quite different.
The reason is that the code is based on formulas that have been further optimised.

We have already avoided using division in the Montgomery ladder step by moving to projective coordinates.
To further improve the performance, we will aim to reduce the number of finite field multiplications as far as possible, since they are generally the most expensive operations after division.
We ignore additions and subtractions since they are cheap by comparison.

If we break down the formulas~\eqref{eq:ladder-step} into one multiplication per equation, reusing common sub-expressions where possible, we see that each step of the ladder requires 14 multiplications:
\begin{align*}
    v_1 &= X_i^2    & v_5    &= A v_3                   & v_6 &= X_i X_{i+1}    & v_{10}   &= (v_8 - v_9)^2 \\
    v_2 &= Z_i^2    & X_{2i} &= (v_1 - v_2)^2           & v_7 &= Z_i Z_{i+1}    & X_{2i+1} &= (v_6 - v_7)^2 \\
    v_3 &= X_i Z_i  & Z_{2i} &= v_4\,(v_1 + v_5 + v_2)  & v_8 &= X_i Z_{i+1}    & Z_{2i+1} &= x_P v_{10}    \\
    v_4 &= 4 v_3    &        &                          & v_9 &= X_{i+1} Z_i
\end{align*}
Some authors count multiplication by a constant ($4$ or $A$, in the case of $v_4$ and $v_5$) and squaring separately from multiplication.
However, our implementation uses the same multiplication function in all cases, so for simplicity we count all types of multiplication equally.

\begin{listing}
\begin{minted}[linenos]{c}
typedef long long i64;
typedef i64 field_elem[16];
static const field_elem _121665 = {0xDB41, 1};

void scalarmult(u8 *out, const u8 *scalar, const u8 *point)
{
  u8 clamped[32];
  i64 bit, i;
  field_elem a, b, c, d, e, f, x;
  for (i = 0; i < 32; ++i) clamped[i] = scalar[i];
  clamped[0] &= 0xf8;
  clamped[31] = (clamped[31] & 0x7f) | 0x40;
  unpack25519(x, point);
  for (i = 0; i < 16; ++i) {
    b[i] = x[i];
    d[i] = a[i] = c[i] = 0;
  }
  a[0] = d[0] = 1;
  for (i = 254; i >= 0; --i) {
    bit = (clamped[i >> 3] >> (i & 7)) & 1;
    swap25519(a, b, bit);
    swap25519(c, d, bit);
    fadd(e, a, c);
    fsub(a, a, c);
    fadd(c, b, d);
    fsub(b, b, d);
    fmul(d, e, e);
    fmul(f, a, a);
    fmul(a, c, a);
    fmul(c, b, e);
    fadd(e, a, c);
    fsub(a, a, c);
    fmul(b, a, a);
    fsub(c, d, f);
    fmul(a, c, _121665);
    fadd(a, a, d);
    fmul(c, c, a);
    fmul(a, d, f);
    fmul(d, b, x);
    fmul(b, e, e);
    swap25519(a, b, bit);
    swap25519(c, d, bit);
  }
  finverse(c, c);
  fmul(a, a, c);
  pack25519(out, a);
}
\end{minted}
\caption{The Montgomery ladder for scalar multiplication.}\label{code:scalarmult}
\end{listing}

In contrast to the above 14 multiplications, the implementation in \autoref{code:scalarmult} uses only 10 multiplications per step.
In this section we focus on how to derive this algorithm from the formulas~\eqref{eq:ladder-step}.
The main ladder loop in lines~19 to~43 of \autoref{code:scalarmult} performs the following operations:
\begin{itemize}
    \item \verb|bit = (clamped[i >> 3] >> (i & 7)) & 1| sets \verb|bit| to be the \verb|i|th bit from the little-endian byte array \verb|clamped| (which was previously set to be a copy of the parameter \verb|scalar|, with a few tweaks explained later).
    \item \verb|swap25519(a, b, bit)| examines \verb|bit|, which is either 0 or 1.
        If \verb|bit == 0|, the function does nothing.
        If \verb|bit == 1|, the function swaps the values in the two variables \verb|a| and \verb|b|.
        It does this in constant time, so the ``do nothing'' case takes the same execution time as the swapping case.
    \item \verb|fadd|, \verb|fsub|, and \verb|fmul| perform field element addition, subtraction, and multiplication, as defined in \autoref{sec:field-arithmetic}.
\end{itemize}

Each iteration of the loop takes as input the values in variables \verb|a|, \verb|b|, \verb|c|, \verb|d|, \verb|x|, and \verb|clamped|, as well as the constant \verb|_121665 = {0xDB41,1}|, which contains the number \verb|0x1DB41| = 121665 (split into 16-bit chunks using the \verb|field_elem| representation).
As output it writes new values to the variables \verb|a|, \verb|b|, \verb|c|, and \verb|d|.
Moreover, it uses \verb|e| and \verb|f| as temporary variables.
In the code of \autoref{code:scalarmult}, variables are reused.
For better readability, we give a new name to each variable assignment in the following breakdown of the operations.
The 18 arithmetic operations in the Montgomery ladder loop (10 multiplications/squarings and 8 additions/subtractions) compute the following expressions:
\begingroup
\allowdisplaybreaks
\begin{align*}
    & \texttt{fadd(e, a, c);} & v_1    &= a + c \\
    & \texttt{fsub(a, a, c);} & v_2    &= a - c \\
    & \texttt{fadd(c, b, d);} & v_3    &= b + d \\
    & \texttt{fsub(b, b, d);} & v_4    &= b - d \\
    & \texttt{fmul(d, e, e);} & v_5    &= v_1^2          &&= (a + c)^2 \\
    & \texttt{fmul(f, a, a);} & v_6    &= v_2^2          &&= (a - c)^2 \\
    & \texttt{fmul(a, c, a);} & v_7    &= v_3 \cdot v_2  &&= (b + d)\,(a - c) = ab - bc + ad - cd \\
    & \texttt{fmul(c, b, e);} & v_8    &= v_4 \cdot v_1  &&= (b - d)\,(a + c) = ab + bc - ad - cd \\
    & \texttt{fadd(e, a, c);} & v_9    &= v_7 + v_8      &&= 2\,(ab - cd) \\
    & \texttt{fsub(a, a, c);} & v_{10} &= v_7 - v_8      &&= 2\,(ad - bc) \\
    & \texttt{fmul(b, a, a);} & v_{11} &= v_{10}^2       &&= 4\,(ad - bc)^2 \\
    & \texttt{fsub(c, d, f);} & v_{12} &= v_5 - v_6      &&= (a + c)^2 - (a - c)^2 = a^2 + 2ac + c^2 - a^2 + 2ac - c^2 = 4ac \\
    & \texttt{fmul(a, c, {\char`_}121665);} & v_{13} &= 121665 \cdot v_{12} &&= 486660\, ac = (A - 2)\,ac \\
    & \texttt{fadd(a, a, d);} & v_{14} &= v_{13} + v_5   &&= (A - 2)\,ac + a^2 + 2ac + c^2 = a^2 + Aac + c^2 \\
    & \texttt{fmul(c, c, a);} & v_{15} &= v_{12} \cdot v_{14} &&= 4ac\, (a^2 + Aac + c^2) \\
    & \texttt{fmul(a, d, f);} & v_{16} &= v_5 \cdot v_6  &&= (a + c)^2\,(a - c)^2 = (a^2 + 2ac + c^2)\,(a^2 - 2ac + c^2) \\
    &                       &        &                 &&= a^4 + 2a^3 c + a^2 c^2 - 2a^3 c - 4 a^2 c^2 - 2a c^3 + a^2 c^2 + 2a c^3 + c^4 \\
    &                       &        &                 &&= a^4 - 2a^2 c^2 + c^4 = (a^2 - c^2)^2 \\
    & \texttt{fmul(d, b, x);} & v_{17} &= v_{11} \cdot x &&= 4x\,(ad - bc)^2 \\
    & \texttt{fmul(b, e, e);} & v_{18} &= v_9^2          &&= 4\,(ab - cd)^2
\end{align*}
\endgroup

Let $a = X_i$, $b = X_{i+1}$, $c = Z_i$, $d = Z_{i+1}$, and $x = x_P$ at the start of a loop iteration.
Further let \verb|bit| be 0, so the \verb|swap25519| operations have no effect.
Then the expressions above match the equations \eqref{eq:ladder-step} with $A = 486662$, $v_{16} = X_{2i}$, $v_{18} = 4X_{2i+1}$, $v_{15} = Z_{2i}$, and $v_{17} = 4Z_{2i+1}$.
The values $(v_{16}, v_{18}, v_{15}, v_{17})$ are written to variables \verb|a|, \verb|b|, \verb|c|, and \verb|d| respectively, forming the input to the next iteration.

If \verb|bit| is 1, the values in \verb|a| and \verb|b| are swapped before and after the computation of these expressions, and likewise the values in \verb|c| and \verb|d| are swapped.
Thus, the inputs to the computation are $a = X_{i+1}$, $b = X_i$, $c = Z_{i+1}$, and $d = Z_i$, and the outputs are $v_{16} = X_{2i+2}$, $v_{18} = 4X_{2i+1}$, $v_{15} = Z_{2i+2}$, and $v_{17} = 4Z_{2i+1}$.
After the final swaps, the variables \verb|a|, \verb|b|, \verb|c|, and \verb|d| contain the values $(v_{18}, v_{16}, v_{17}, v_{15})$.

Thus, each loop iteration maps the input tuple $(X_i, Z_i, X_{i+1}, Z_{i+1})$ to either the output tuple $(X_{2i}, Z_{2i}, 4X_{2i+1}, 4Z_{2i+1})$ or the output tuple $(4X_{2i+1}, 4Z_{2i+1}, X_{2i+2}, Z_{2i+2})$ depending on the value of \verb|bit|.
This exactly matches the Montgomery ladder step~\eqref{eq:ladder}, except for the additional factor of 4 in $X_{2i+1}$ and $Z_{2i+1}$.
However, since these two variables are just an expanded representation of the fraction $x_{2i+1} = X_{2i+1}/Z_{2i+1}$, these two factors of 4 cancel out and have no effect on the final result.

\subsection{Clamping}\label{sec:clamping}

We now turn to the first few lines of the \verb|scalarmult| function.

The scalar parameter \verb|scalar| is assumed to be a uniformly distributed random array of 32 bytes.
First, \verb|scalar| is copied to \verb|clamped|, and then five bits of \verb|clamped| are set to constant values.
\verb+clamped[0] &= 0xf8+ sets the three least significant bits to 0.
\verb+clamped[31] = (clamped[31] & 0x7f) | 0x40+ sets the most significant bit to 0, and the second-most-significant bit to 1.
This process is known as \emph{clamping}~\cite{Madden:2020}.

Setting the three least significant bits to 0 ensures that \verb|clamped| is a multiple of 8.
By also setting the most significant bit to 0, \verb|clamped| becomes a number of the form $hk$, where $h=8$ and $k$ is a uniformly distributed random number from the range $[0,\, 2^{252}-1]$.
As explained in \autoref{sec:cofactor}, making \verb|clamped| a multiple of the cofactor $h=8$ prevents small subgroup confinement attacks.
The upper end of the range, $2^{252}-1$, is slightly below $q = 2^{252} + 27742317777372353535851937790883648493$, the order of the base point/generator.
Choosing $k$ from the range $[0,\, 2^{252}-1]$ is, in practice, equivalent to using the range $[0,\, q-1]$: when using the latter range, the probability of picking a value in the range $[2^{252}, q-1]$ is approximately $10^{-38}$.

The reason for setting the second-most-significant bit to 1 is unrelated to the cofactor: it is instead a precaution to help ensure constant-time implementations.
If this bit was zero, then an implementation of scalar multiplication could save the first iteration of the Montgomery ladder without affecting the result; an adversary could then use this timing variation to leak the most significant bit of the private key (and perhaps more).
Setting this bit to one forces the Montgomery ladder to always use the full 255 iterations.
Our implementation would be constant-time even without setting this bit to 1, but X25519 is defined to always have this bit set as a precaution to protect less careful implementations.

After clamping, \verb|clamped| is a number of the form $8k$, where $k \in [2^{251},\, 2^{252}-1]$.
Thus, the distribution of group elements produced by X25519 is non-uniform: only about half of the group elements in the subgroup of order $q$ will be generated.
However, this non-uniformity does not significantly weaken the security of X25519 for Diffie-Hellman purposes (apart from the loss of 1 bit of entropy).
% TODO: does this mean that the decision Diffie-Hellman problem is technically not hard for X25519?
% https://cr.yp.to/highspeed/naclcrypto-20090310.pdf says: "the set of possibilities for k is an easy-to-recognise set"

% https://moderncrypto.org/mail-archive/curves/2017/000860.html
A final reason for clamping: if $k=0$ or $k$ is a multiple of $q$, then we would expect $P^k = \infty$ for a base point $P$ of order $q$.
Although the Montgomery ladder correctly handles the point at infinity as an intermediate value, as shown in \autoref{sec:handling-infinity}, \verb|scalarmult| does not have the ability to return the point at infinity, since the function only returns an $x$ coordinate of a curve point.
If there was no clamping and a scalar argument of $0$ or $q$ were passed in, \verb|scalarmult| would return zero, which the caller cannot distinguish from the curve point whose $x$ coordinate is zero.
Returning an error in this case would make the function non-constant-time, if not done carefully.

By forcing $k$ to be within $0 < k < q$, clamping avoids ever needing to return $\infty$ (except in the case where an adversary provides a group element with small order, as discussed in \autoref{sec:cofactor}, in which case it's fine to return zero).
In the course of Diffie-Hellman with a base point of prime order $q$, $\infty$ will never be generated, since $(P^j)^k = P^{jk} = \infty$ only if $jk$ is a multiple of $q$, which is only possible if $j$ or $k$ is a multiple of $q$.

\subsection{Finishing off scalar multiplication}

At the start of \verb|scalarmult|, the $x$ coordinate of the base point is passed in as parameter \verb|point|.
On line~13 this byte array is translated into \verb|field_elem| representation and copied to \verb|x|.
We then initialise $\verb|a|=1$, $\verb|b|=\verb|x|$, $\verb|c|=0$, and $\verb|d|=1$.
This gives us the starting state of the Montgomery ladder as defined in equation~\eqref{eq:ladder}: $L(P, 0) = (\frac{a}{c}, \frac{b}{d}) = (\infty, P)$.

After the Montgomery ladder is finished, \verb|a| and \verb|c| contain the numerator and denominator of the $x$ coordinate of curve point $P^\mathit{clamped}$.
In order to return this value, we must first convert projective coordinates back into affine coordinates by dividing the two, as discussed in \autoref{sec:inverse}: we use the \verb|finverse| function to replace \verb|c| with its multiplicative inverse, and then multiply \verb|a| and \verb|c| using \verb|fmul|.

Finally, we use the \verb|pack25519| function, described in \autoref{sec:pack}, to convert the \verb|field_elem| representation of the result back into an array of 32 bytes, and we write the result to the output variable \verb|out|.
This value can now be used as a public key (if \verb|point| was the base point), or as shared secret to initialise a symmetric encryption scheme (if \verb|point| was a public key or the group element received from the other user), as shown in \autoref{sec:ecdh}.

\section{Conclusions}

This paper has shown how to derive the X25519 implementation in TweetNaCl, line by line, from first principles.
Starting by assuming only minimal mathematical background knowledge we have explored how modern, constant-time cryptography is implemented, and justified the correctness of this implementation.
Although we have only studied one particular implementation, other implementations such as libsodium share many principles with the code studied here; after reading this paper, you will find it much easier to figure out what other implementations are doing.

For future work it would be interesting to expand this discussion to other common algorithms in elliptic curve cryptography, such as the Ed25519 signature scheme, and other curves such as NIST curves and the secp256k1 curve used by Bitcoin.
The Ristretto255 prime-order group~\cite{Ristretto255}, which eliminates the cofactor of Curve25519, would also be interesting to discuss.
I believe that by carefully studying existing implementations of cryptographic algorithms, and by analysing in detail what makes them correct, we can gain a deeper understanding of cryptography in general and improve the quality of implementations of cryptographic protocols.

% Twist security https://safecurves.cr.yp.to/twist.html

% Ed25519 clamping https://twitter.com/FiloSottile/status/1403651113665110016
% Discussion of clamping https://twitter.com/Sc00bzT/status/1270331532490747904
% More on clamping https://www.jcraige.com/an-explainer-on-ed25519-clamping

% Google's implementation of Curve25519
% https://github.com/google/tink/blob/master/java_src/src/main/java/com/google/crypto/tink/subtle/Curve25519.java
% https://github.com/google/tink/blob/master/java_src/src/main/java/com/google/crypto/tink/subtle/Field25519.java
% uses the word "limbs" to refer to what I call "elements"
% curve25519 paper calls them "coefficients", and 2^16 the "radix"

% Synthesising formally verified field arithmetic:
% https://twitter.com/FiloSottile/status/1388374868131987459
% https://github.com/mit-plv/fiat-crypto
% http://adam.chlipala.net/papers/FiatCryptoSP19/FiatCryptoSP19.pdf

% The dangers of not using constant-time arithmetic: https://eprint.iacr.org/2017/806.pdf

% Constant-time Euclid's algorithm: https://gcd.cr.yp.to/
% https://twitter.com/pwuille/status/1360347812588707840
% https://eprint.iacr.org/2021/549

% Optimised addition chains for field inversion based on Fermat's little theorem:
% https://github.com/mmcloughlin/addchain

% Other things to look at: NIST P-256 curve; Ed25519; secp256k1 ECDSA (bitcoin); petlib https://petlib.readthedocs.io/en/latest/
% edwards25519 decoding formulas https://buttondown.email/cryptography-dispatches/archive/cryptography-dispatches-re-deriving-the/
% EC-KCDSA https://github.com/trevorbernard/curve25519-java/blob/master/src/main/java/djb/Curve25519.java
% Ristretto255 https://ietf.org/id/draft-irtf-cfrg-ristretto255-00.html

% Prefer "machine in the middle" or "person in the middle" over "man in the middle"

% Threshold signatures
% https://eprint.iacr.org/2020/1390
% https://eprint.iacr.org/2018/987
% FROST: https://eprint.iacr.org/2020/852 https://twitter.com/veorq/status/1370292261720842240

% PAKE, such as https://github.com/jedisct1/cpace or socialist millionaire protocol or J-PAKE
% https://en.wikipedia.org/wiki/Password_Authenticated_Key_Exchange_by_Juggling
% https://tools.ietf.org/id/draft-irtf-cfrg-spake2-10.html
% https://mailarchive.ietf.org/arch/msg/cfrg/HssFKRoUdM2kyVt4T9j_KPZqAmE/
% https://datatracker.ietf.org/meeting/104/materials/slides-104-cfrg-pake-selection-01
% Attack on SPAKE2 https://redrocket.club/posts/croc/
% https://emilymstark.com/2021/02/01/padding-partitioning-oracles-and-another-hot-take-on-pakes.html

% Anonymous credentials https://eprint.iacr.org/2019/460.pdf

% Elligator
% Blinding (as used e.g. in Sphinx)
% If this is going to be a textbook, add more examples and exercises

% Zero-knowledge proofs
% ZCash specification https://zips.z.cash/protocol/protocol.pdf
% Notes on zero-knowledge proofs https://www.notion.so/martinkl/Zero-knowledge-proofs-SNARKs-zkSNARKs-927756c7122948439079f4d41794104f
% Bulletproofs ZKP https://crypto.stanford.edu/bulletproofs/
% Supersonic ZKP https://web.archive.org/web/20200920083031/http://eprint.iacr.org/2019/1229
% https://github.com/arkworks-rs/snark
% https://twitter.com/JoshuaWBaron/status/1384217010419101697

% Pairing
% https://crypto.stanford.edu/pbc/notes/elliptic/
% https://crypto.stanford.edu/pbc/notes/ep/
% https://crypto.stanford.edu/pbc/
% https://tools.ietf.org/html/draft-irtf-cfrg-bls-signature-04
% Bugs in pairing-based BLS signatures https://eprint.iacr.org/2021/323.pdf

% Assembly: try this? https://github.com/mmcloughlin/avo

% Elliptic curve cryptography in practice https://eprint.iacr.org/2013/734.pdf

% How not to do it: https://soatok.blog/2020/07/08/gnu-a-heuristic-for-bad-cryptography/

\begin{acks}
Thank you to Alastair Beresford, Daniel Hugenroth, Markus Kuhn, and Alex Mason for feedback on a draft of this paper.
I am grateful for financial support from a Leverhulme Trust Early Career Fellowship, the Isaac Newton Trust, Nokia Bell Labs, and crowdfunding supporters including Ably, Adri{\` a} Arcarons, Chet Corcos, Macrometa, Mintter, David Pollak, RelationalAI, SoftwareMill, Talent Formation Network, and Adam Wiggins.
\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\appendix
\section{Differences to the Original TweetNaCl}\label{sec:appendix}

The code listings in this paper are based on version 20140427 of Bernstein et al.'s TweetNaCl implementation~\cite{TweetNaCl}.
I have made a number of changes in the interest of readability; these changes do not affect the functionality or the constant-time property of the code.
This appendix details those changes.

\begin{itemize}
    \item All functions that are not part of the X25519 implementation are omitted.
    \item All uses of the \verb|FOR| and \verb|sv| macros are replaced with their definitions.
    \item The \verb|gf| type definition is renamed to \verb|field_elem|.
    \item I added whitespace around operators to improve readability.
    \item In the \verb|unpack25519| function the parameters \verb|o| and \verb|n| are renamed to \verb|out| and \verb|in|, respectively.
    \item The \verb|car25519| function is renamed to \verb|carry25519|, its parameter \verb|o| is renamed to \verb|elem|, and its local variable \verb|c| is renamed to \verb|carry|.
        Its loop body originally read:
\begin{minted}{c}
    o[i]+=(1LL<<16);
    c=o[i]>>16;
    o[(i+1)*(i<15)]+=c-1+37*(c-1)*(i==15);
    o[i]-=c<<16;
\end{minted}
        The addition of $2^{16}$ to \verb|o[i]| and the subsequent subtraction of $1$ from \verb|o[i+1]| cancel out and serve no apparent purpose, so I removed them.
        I hypothesise that perhaps the addition of $2^{16}$ was supposed to ensure that \verb|o[i]| is non-negative, but this is not true because it is possible to have $\texttt{o[i]} < -2^{16}$, and it is not necessary because the code handles negative values correctly anyway.
        Dan Bernstein and Tanja Lange did not respond to my emails requesting a clarification of these lines of code.
        My simplified version of the loop body also replaces the hard-to-read ``multiply-by-boolean'' idiom with a simple if statement:
\begin{minted}{c}
    carry = elem[i] >> 16;
    elem[i] -= carry << 16;
    if (i < 15) elem[i + 1] += carry; else elem[0] += 38 * carry;
\end{minted}
        It is safe to perform a conditional branch on the value of \verb|i| since it is not a secret (it always ranges from 0 to 15).
    \item The \verb|A| function is renamed to \verb|fadd|, and its parameter \verb|o| is renamed to \verb|out|.
    \item The \verb|Z| function is renamed to \verb|fsub|, and its parameter \verb|o| is renamed to \verb|out|.
    \item The \verb|M| function is renamed to \verb|fmul|, its parameter \verb|o| is renamed to \verb|out|, and its local variable \verb|t| is renamed to \verb|product|.
    \item I removed the \verb|S| (square) function, which only called \verb|M| anyway, and replaced it with calls to \verb|fmul|.
    \item The \verb|inv25519| function is renamed to \verb|finverse|, its parameters \verb|o| and \verb|i| are renamed to \verb|out| and \verb|in| respectively, and its local variable \verb|a| is renamed to \verb|i| (since it is used as loop counter).
    \item The \verb|sel25519| function is renamed to \verb|swap25519|, and its parameter \verb|b| is renamed to \verb|bit|.
    \item In the \verb|pack25519| function the parameters \verb|o| and \verb|n| are renamed to \verb|out| and \verb|in| respectively, and the local variable \verb|b| is renamed to \verb|carry|.
    \item The \verb|crypto_scalarmult_base| function is renamed to \verb|scalarmult_base|, and its parameters \verb|q| and \verb|n| are renamed to \verb|out| and \verb|scalar|, respectively.
    \item The \verb|crypto_box_keypair| function is renamed to \verb|generate_keypair|, and its parameters \verb|y| and \verb|x| are renamed to \verb|pk| and \verb|sk|, respectively.
    \item The \verb|x25519| function is added as an alias of \verb|scalarmult|.
    \item The \verb|crypto_scalarmult| function is renamed to \verb|scalarmult|, its parameters \verb|q|, \verb|n| and \verb|p| are renamed to \verb|out|, \verb|scalar| and \verb|point|, respectively, and its local variables \verb|z| and \verb|r| are renamed to \verb|clamped| and \verb|bit|, respectively.
        The first loop's upper bound is changed from 31 to 32 and the following two lines (which perform the clamping) are slightly refactored to make the code clearer without changing its behaviour.
        I have changed the variable \verb|x|, which was originally an 80-element array of \verb|i64|, to be of type \verb|field_elem| (i.e.\ a 16-element array of \verb|i64|) instead.
        The first 16 elements of \verb|x| have the same function as they did originally (namely, the internal representation of the $x$ coordinate of the input point).
        The original code, after completing the Montgomery ladder, copies the value of local variable \verb|a| to indexes $16 \dots 31$ of \verb|x|, \verb|c| to indexes $32 \dots 47$, \verb|b| to indexes $48 \dots 63$, and \verb|d| to indexes $64 \dots 79$, and then performs the last three function calls (the inversion of \verb|c|, the multiplication of \verb|a| and \verb|c|, and the \verb|pack25519| of the result) on offsets of the variable \verb|x|.
        The purpose of copying \verb|a|, \verb|b|, \verb|c| and \verb|d| to \verb|x| is unclear, since nothing ever uses the fact that these values have been copied into one contiguous array.
        Perhaps it is a remnant of earlier debugging logic?
        Dan Bernstein and Tanja Lange did not respond to my emails requesting a clarification of why this is happening.
        I therefore removed the copying into \verb|x| and changed the last three function calls of \verb|scalarmult| to operate directly on \verb|a| and \verb|c| instead.
\end{itemize}

I have run the modified code with the test vectors provided as part of the NaCl package~\cite{NaCl}, and checked that they compute the same result.

\end{document}
